{
  
    
        "post0": {
            "title": "Using the RDKit in a C++ program",
            "content": "Note: the instructions in this blog post currently only work on linux systems. There’s a configuration problem with the way we use cmake on the Mac and Windows that needs to be cleared up. I will update the post after that’s done. . Last week I (re)discoverered that it’s pretty easy to use the RDKit in other C++ projects. This is obviously somthing that’s possible, but I thought of it as being something of a pain. It turns out that it’s not, as I hope to show you in this post. . I started by setting up a fresh conda environment and grabbing an RDKit build from conda-forge, this is a bit heavyweight since you end up with a bunch of python packages as well as the RDKit itself (I’m going to look into making this more minimal), but it’s much easier than doing your own build. . The first thing is to set up a conda environment: . conda create -n rdkit_dev conda activate rdkit_dev conda install -c conda-forge mamba mamba install -c conda-forge cmake rdkit eigen . Note: I start by installing mamba here because it makes doing conda installs much, much faster. . Here’s a simple demo program which reads in a set of molecules from an input file and generates tautomer hashes for them. It uses the boost::timer library in order to separately time how long it takes to read the molecules and generate the hashes. I called this file tautomer_hash.cpp: . #include &lt;GraphMol/FileParsers/MolSupplier.h&gt; #include &lt;GraphMol/MolHash/MolHash.h&gt; #include &lt;GraphMol/RDKitBase.h&gt; #include &lt;RDGeneral/RDLog.h&gt; #include &lt;algorithm&gt; #include &lt;boost/timer/timer.hpp&gt; #include &lt;iostream&gt; #include &lt;vector&gt; using namespace RDKit; void readmols(std::string pathName, unsigned int maxToDo, std::vector&lt;RWMOL_SPTR&gt; &amp;mols) { boost::timer::auto_cpu_timer t; // using a supplier without sanitizing the molecules... RDKit::SmilesMolSupplier suppl(pathName, &quot; t&quot;, 1, 0, true, false); unsigned int nDone = 0; while (!suppl.atEnd() &amp;&amp; (maxToDo &lt;= 0 || nDone &lt; maxToDo)) { RDKit::ROMol *m = suppl.next(); if (!m) { continue; } m-&gt;updatePropertyCache(); // the tautomer hash code uses conjugation info MolOps::setConjugation(*m); nDone += 1; mols.push_back(RWMOL_SPTR((RWMol *)m)); } std::cerr &lt;&lt; &quot;read: &quot; &lt;&lt; nDone &lt;&lt; &quot; mols.&quot; &lt;&lt; std::endl; } void generatehashes(const std::vector&lt;RWMOL_SPTR&gt; &amp;mols) { boost::timer::auto_cpu_timer t; for (auto &amp;mol : mols) { auto hash = MolHash::MolHash(mol.get(), MolHash::HashFunction::HetAtomTautomer); } } int main(int argc, char *argv[]) { RDLog::InitLogs(); std::vector&lt;RWMOL_SPTR&gt; mols; BOOST_LOG(rdInfoLog) &lt;&lt; &quot;read mols&quot; &lt;&lt; std::endl; readmols(argv[1], 10000, mols); BOOST_LOG(rdInfoLog) &lt;&lt; &quot;generate hashes&quot; &lt;&lt; std::endl; generatehashes(mols); BOOST_LOG(rdInfoLog) &lt;&lt; &quot;done &quot; &lt;&lt; std::endl; } . This is a pretty crappy program since it doesn’t do much error checking, but the purpose here is to demonstrate how to get the environment setup, not to teach how to write nice C++ programs. :-) . The way to make the build easy is to use cmake to set everything up, so I need a CMakeLists.txt file that defines my executable and its RDKit dependencies: . cmake_minimum_required(VERSION 3.18) project(simple_cxx_example) set(CMAKE_CXX_STANDARD 14) set(CMAKE_CXX_STANDARD_REQUIRED True) find_package(RDKit REQUIRED) find_package(Boost COMPONENTS timer system REQUIRED) add_executable(tautomer_hash tautomer_hash.cpp) target_link_libraries(tautomer_hash RDKit::SmilesParse RDKit::MolHash Boost::timer) . This tells cmake to find the RDKit and boost installs (which “just works” since cmake, boost, and the RDKit were all installed from conda), defines the executable I want to create, and then lists the RDKit and boost libraries I use. And that is pretty much that. . Now I create a build dir, run cmake to setup the build, and run make to actually build my program: . (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example$ mkdir build (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example$ cd build (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example/build$ cmake .. -- The C compiler identification is GNU 9.3.0 -- The CXX compiler identification is GNU 9.3.0 -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working C compiler: /usr/bin/cc - skipped -- Detecting C compile features -- Detecting C compile features - done -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /usr/bin/c++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Performing Test CMAKE_HAVE_LIBC_PTHREAD -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found Boost: /home/glandrum/miniconda3/envs/rdkit_dev/lib/cmake/Boost-1.74.0/BoostConfig.cmake (found suitable version &quot;1.74.0&quot;, minimum required is &quot;1.74.0&quot;) -- Found Boost: /home/glandrum/miniconda3/envs/rdkit_dev/lib/cmake/Boost-1.74.0/BoostConfig.cmake (found version &quot;1.74.0&quot;) found components: timer system -- Configuring done -- Generating done -- Build files have been written to: /home/glandrum/RDKit_blog/src/simple_cxx_example/build (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example/build$ make tautomer_hash [ 50%] Building CXX object CMakeFiles/tautomer_hash.dir/tautomer_hash.cpp.o [100%] Linking CXX executable tautomer_hash [100%] Built target tautomer_hash . And now I can run the program: . (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example/build$ ./tautomer_hash /scratch/RDKit_git/Code/Profiling/GraphMol/chembl23_very_active.txt [07:51:33] read mols read: 10000 mols. 0.819242s wall, 0.740000s user + 0.070000s system = 0.810000s CPU (98.9%) [07:51:33] generate hashes 0.872662s wall, 0.870000s user + 0.010000s system = 0.880000s CPU (100.8%) [07:51:34] done (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example/build$ . If you don’t feel like copy/pasting, the source files for this post are available from github. . Next step: add this to the documentation! .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/technical/2021/07/24/setting-up-a-cxx-dev-env.html",
            "relUrl": "/tutorial/technical/2021/07/24/setting-up-a-cxx-dev-env.html",
            "date": " • Jul 24, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Simulating count fingerprints",
            "content": "Many of the RDKit&#39;s fingerprints are available as either bit vectors or count vectors. Bit vectors track whether or not features appear in a molecule while count vectors track the number of times each feature appears. It seems intuitive that a count vector is a better representation of similarity than bit vectors, but we often use bit vector representations for computational expediency - bit vectors require less memory and are much faster to operate on. . What impact does this using bit vectors have on computed similarity values and the ordering of similarities? This notebook attempts to provide at least a partial answer to that question and also examines a strategy for simulating counts using bit vectors. I look at the following fingerprints: . Morgan 2 | Topological Torsion | Atom Pair | RDKit | . And I use two sets of compunds: . Random pairs of compounds taken from this blog post | Pairs of &quot;related compounds&quot; taken from this blog post | . Bit vector similarity vs count-based similarity . Let&#39;s start with two molecules where this makes a big difference: The calculated similarity with MFP2 and counts is 0.6 while with bits it&#39;s 0.29. That&#39;s easy to understand since with the bit-based fingerprints the long alkyl chains don&#39;t make the large ontribution to the similarity that they do when using counts. . To demonstrate that this isn&#39;t all about long chains, here&#39;s another pair where there&#39;s a significant difference: In this case the count-based similarity is 0.59 while with bits it&#39;s 0.35. . Those were a couple of anecdotes, but let&#39;s look at the differences across the entire datasets: Here I&#39;ve plotted bit-based similarity vs count-based similarity and included statistics on the correlation in the title. The left plot is for the random compound pairs and the right plot is for the related compound pairs. There are significant differences in similarity here, with the bit vector similarities being consistently lower than the count-based equivalent, but it&#39;s worth pointing out that the rankings of the similarities (as measured by the Spearman rank-order correlation values) are reasonably equivalent, particularly for the related compound pairs. . The equivalent plots for the RDKit fingerprint show the same qualitative behavior with the difference that bit vector similarities tend to be higher than count based similarities: . Simulating counts . The RDKit has a simple mechanism for simulating counts using bit vectors: set multiple bits for each feature where the number of bits set is determined by the count. The approach uses a fixed number of potential bits which each have a threshold value; if the count for the feature exceeds the threshold value then the corresponding bit is set. Here&#39;s a schematic illustration for count simulation with four bits and the thresholds 1, 2, 4, and 8: The example shown, with the first two bits set for feature N, is what we&#39;d get if feature N is set either 2 or 3 times in a molecule. Note that we aren&#39;t just using a binary representation of the count itself. In that case a feature which is present one time in the first molecule, representation 1000, and two times in the second molecule, representation 0100, would contribute zero to the overall similarity. That&#39;s not desirable. . Note that since the count simulation approach uses multiple bits per feature, it decreases the effective length of the fingerprint by a factor equal to the number of bits used. With the default setting of four bits per feature a 2048 bit fingerprint will have the same number of bit collisions as a 512 bit fingerprint without count simulation. This becomes more relevant the more bits a fingerprint tends to set. For example using count simulation to calculate similarity with the RDKit fingerprint, which sets a large number of bits, actually decreases the correlation with the similarity calculated with count vectors (see below for the plot) unless I also increase the overall length of the fingerprint. . Results and discussion . Here&#39;s a summary of the results for the fingerprints I examine here . Random pairs Bits--Count Count simulation--Count . Fingerprint Spearman r MAE RMSE Spearman r MAE RMSE Note . Morgan 2 | 0.84 | 0.097 | 0.10 | 0.90 | 0.024 | 0.036 | | . Topological torsions | 0.92 | 0.026 | 0.051 | 0.98 | 0.018 | 0.029 | | . Topological torsions | 0.92 | 0.026 | 0.051 | 0.99 | 0.010 | 0.021 | 8192 bits for count simulation | . Atom pairs | 0.82 | 0.031 | 0.049 | 0.90 | 0.055 | 0.066 | | . Atom pairs | 0.82 | 0.031 | 0.049 | 0.96 | 0.014 | 0.023 | 8192 bits for count simulation | . RDKit | 0.83 | 0.079 | 0.10 | 0.94 | 0.029 | 0.045 | 8192 bits for count simulation | . Related pairs Bits--Count Count simulation--Count . Fingerprint Spearman r MAE RMSE Spearman r MAE RMSE Note . Morgan 2 | 0.94 | 0.043 | 0.062 | 0.98 | 0.019 | 0.028 | | . Topological torsions | 0.90 | 0.050 | 0.079 | 0.98 | 0.021 | 0.035 | | . Topological torsions | 0.90 | 0.050 | 0.079 | 0.98 | 0.018 | 0.032 | 8192 bits for count simulation | . Atom pairs | 0.91 | 0.043 | 0.067 | 0.97 | 0.052 | 0.063 | | . Atom pairs | 0.91 | 0.043 | 0.067 | 0.98 | 0.020 | 0.032 | 8192 bits for count simulation | . RDKit | 0.91 | 0.077 | 0.11 | 0.98 | 0.034 | 0.053 | 8192 bits for count simulation | . Using the count simulation strategies does improve the match between similarities calculated with bit vectors and those calculated with count vectors. The differences are statistically significant (results not shown here) and large enough to potentially be meaningful. MAE and RMSE values for the various fingerprints typically decrease by at least a factor of two and Spearman rank-order correlation in general increases quite a bit. These conclusions hold for both randomly paired molecules and related pairs with more dramatic differences seen at the lower ends of the similarity scale (the random pairs). . Note that this analysis focuses solely on similarity. The extra information added by doing count simulation will most likely also influence the performance of machine learning models built using these fingerprints. But that&#39;s for a future blog post. . The code to reproduce all of this, along with more plots, is below. . from rdkit import Chem from rdkit.Chem import rdFingerprintGenerator from rdkit.Chem import rdMolDescriptors from rdkit import DataStructs from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdDepictor rdDepictor.SetPreferCoordGen(True) import numpy as np from scipy.stats import spearmanr from sklearn.metrics import median_absolute_error, mean_squared_error import rdkit print(rdkit.__version__) %pylab inline . 2021.09.1pre Populating the interactive namespace from numpy and matplotlib . Some technical notes: . Note that this notebook uses a couple of features which did not work properly until the v2021.03.4 of the RDKit (which will be released in July). | Count simulation is only generally available when working with the &quot;new&quot; fingerprint generators, so those are used throughout this notebook. | Count simulation is used by default for atom pair and topological torsion fingerprints, both with the &quot;new&quot; fingerprint generators and the older fingerprinting functions. | . Construct the dataset. . Start with our standard similarity comparison set: . import gzip with gzip.open(&#39;../data/chembl21_25K.pairs.txt.gz&#39;,&#39;rt&#39;) as inf: ls = [x.split() for x in inf.readlines()] ms = [(Chem.MolFromSmiles(x[1]),Chem.MolFromSmiles(x[3])) for x in ls] . That&#39;s weighted towards lower similarity values, get some pairs from the related compounds set: . import pickle from collections import namedtuple MCSRes=namedtuple(&#39;MCSRes&#39;,(&#39;smarts&#39;,&#39;numAtoms&#39;,&#39;numMols&#39;,&#39;avgNumMolAtoms&#39;,&#39;mcsTime&#39;)) data = pickle.load(open(&#39;../data/scaffolds_revisited_again.simplified.pkl&#39;,&#39;rb&#39;)) data2 = pickle.load(open(&#39;../data/scaffolds_expanded.simplified.pkl&#39;,&#39;rb&#39;)) data += data2 # keep only sets where the MCS was at least 50% of the average number of atoms: keep = [x for x in data if x[2].numAtoms&gt;=np.mean(x[2].avgNumMolAtoms)/2] len(keep) import random random.seed(0xf00d) related_pairs = [] # keep only molecules matching the MCS: for i,tpl in enumerate(keep): assay,smis,mcs,svg = tpl patt = Chem.MolFromSmarts(mcs.smarts) smis = [(x,y) for x,y in smis if Chem.MolFromSmiles(y).HasSubstructMatch(patt)] ssmis = smis[:] random.shuffle(ssmis) related_pairs.extend([(x[0],x[1],y[0],y[1]) for x,y in zip(smis,ssmis)][:10]) print(f&#39;{len(related_pairs)} related pairs&#39;) related_ms = [(Chem.MolFromSmiles(x[1]),Chem.MolFromSmiles(x[3])) for x in related_pairs] . 10470 related pairs . len(ms) . 25000 . import random random.seed(0xf00d) indices = list(range(len(ms))) random.shuffle(indices) random_pairs = [ms[x] for x in indices[:5000]] indices = list(range(len(related_ms))) random.shuffle(indices) related_pairs = [related_ms[x] for x in indices[:5000]] . Performance of similarity comparisons . fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=2048,countSimulation=False) bv_pairs = [(fpgen.GetFingerprint(x[0]),fpgen.GetFingerprint(x[1])) for x in random_pairs] cv_pairs = [(fpgen.GetCountFingerprint(x[0]),fpgen.GetCountFingerprint(x[1])) for x in random_pairs] . %timeit _ = [DataStructs.TanimotoSimilarity(x,y) for x,y in bv_pairs] . 5.06 ms ± 75 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) . %timeit _ = [DataStructs.TanimotoSimilarity(x,y) for x,y in cv_pairs] . 8.37 ms ± 160 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) . Not a huge difference there, but what about a fingerprint which sets a much larger number of bits? . fpgen = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=2048,countSimulation=False) bv_pairs = [(fpgen.GetFingerprint(x[0]),fpgen.GetFingerprint(x[1])) for x in random_pairs] cv_pairs = [(fpgen.GetCountFingerprint(x[0]),fpgen.GetCountFingerprint(x[1])) for x in random_pairs] . %timeit _ = [DataStructs.TanimotoSimilarity(x,y) for x,y in bv_pairs] . 6.22 ms ± 404 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) . %timeit _ = [DataStructs.TanimotoSimilarity(x,y) for x,y in cv_pairs] . 189 ms ± 1.53 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) . Here the performance difference is quite noticeable. . Morgan 2 . fpgen1 = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=2048,countSimulation=False) fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in ms] countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in ms] related_fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in related_ms] related_countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in related_ms] . fpgen2 = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=2048,countSimulation=True) fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in related_ms] . delts = sorted([(countsims[i]-fpsims[i],i) for i in range(len(fpsims))]) print(delts[:5]) print(delts[-5:]) . [(-0.20329670329670324, 12408), (-0.19358178053830222, 14793), (-0.19191919191919193, 126), (-0.17673378076062635, 1391), (-0.17493796526054584, 13034)] [(0.31300539083557954, 20013), (0.3151412702245835, 12445), (0.3157622739018088, 13430), (0.3207792207792208, 4381), (0.37206896551724133, 11692)] . idx = 13430 print(f&#39;Count: {countsims[idx]:.2f}, Bits: {fpsims[idx]:.2f}, Simulated counts: {fpsims_countsim[idx]:.2f}&#39;) Draw.MolsToGridImage(ms[idx],subImgSize=(350,250),molsPerRow=2) . Count: 0.60, Bits: 0.29, Simulated counts: 0.42 . delts = sorted([(related_countsims[i]-related_fpsims[i],i) for i in range(len(related_fpsims))]) print(delts[:5]) print(delts[-5:]) . [(-0.26508684133058585, 4359), (-0.24506749740394607, 1322), (-0.2321428571428572, 7602), (-0.21353383458646613, 10080), (-0.20879676440849337, 3804)] [(0.24318181818181822, 1962), (0.24456938410426782, 1961), (0.24456938410426782, 1969), (0.2455492835432045, 1963), (0.273972602739726, 7774)] . idx = 1969 print(f&#39;Count: {related_countsims[idx]:.2f}, Bits: {related_fpsims[idx]:.2f}, Simulated counts: {related_fpsims_countsim[idx]:.2f}&#39;) Draw.MolsToGridImage(related_ms[idx],subImgSize=(350,250),molsPerRow=2) . Count: 0.59, Bits: 0.35, Simulated counts: 0.52 . idx = 4359 print(f&#39;Count: {related_countsims[idx]:.2f}, Bits: {related_fpsims[idx]:.2f}, Simulated counts: {related_fpsims_countsim[idx]:.2f}&#39;) Draw.MolsToGridImage(related_ms[idx],subImgSize=(350,250),molsPerRow=2) . Count: 0.39, Bits: 0.65, Simulated counts: 0.51 . figsize(18,9) subplot(1,2,1) y,x = fpsims,countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) y,x = related_fpsims,related_countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . fpgen3 = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=8192,countSimulation=True) fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in related_ms] figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . Topological Torsions . fpgen1 = rdFingerprintGenerator.GetTopologicalTorsionGenerator(fpSize=2048,countSimulation=False) fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in ms] countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in ms] related_fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in related_ms] related_countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in related_ms] fpgen2 = rdFingerprintGenerator.GetTopologicalTorsionGenerator(fpSize=2048,countSimulation=True) fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in related_ms] . figsize(18,9) subplot(1,2,1) y,x = fpsims,countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) y,x = related_fpsims,related_countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . fpgen3 = rdFingerprintGenerator.GetTopologicalTorsionGenerator(fpSize=8192,countSimulation=True) fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in related_ms] figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . Atom pairs . fpgen1 = rdFingerprintGenerator.GetAtomPairGenerator(fpSize=2048,countSimulation=False) fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in ms] countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in ms] related_fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in related_ms] related_countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in related_ms] fpgen2 = rdFingerprintGenerator.GetAtomPairGenerator(fpSize=2048,countSimulation=True) fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in related_ms] . figsize(18,9) subplot(1,2,1) y,x = fpsims,countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) y,x = related_fpsims,related_countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . fpgen3 = rdFingerprintGenerator.GetAtomPairGenerator(fpSize=8192,countSimulation=True) fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in related_ms] figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . RDKit Fingerprint . fpgen1 = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=2048,countSimulation=False) fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in ms] countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in ms] related_fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in related_ms] related_countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in related_ms] fpgen2 = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=2048,countSimulation=True) fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in related_ms] . figsize(18,9) subplot(1,2,1) y,x = fpsims,countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) y,x = related_fpsims,related_countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . This is terrible, but I suspect that has to do with the number of bits set by RDKit fingerprints just totally overloading things. . fpgen3 = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=8192,countSimulation=True) fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in related_ms] figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . That&#39;s way better .",
            "url": "https://greglandrum.github.io/rdkit-blog/fingerprints/technical/reference/2021/07/06/simulating-counts.html",
            "relUrl": "/fingerprints/technical/reference/2021/07/06/simulating-counts.html",
            "date": " • Jul 6, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Looking at the number of bits set by different fingerprints",
            "content": "This is an updated version of a post. The original version of the notebook can be found in github. . I&#39;ve done a number of posts looking at Morgan fingerprint statistics before, including: . The number of collisions in Morgan fingerprints. | Morgan fingerprint stats | Collisions in Morgan fingerprints revisited | . I have done similar analysis for other fingerprint types, but it looks like I didn&#39;t post that (at least I can&#39;t find it if I did). It&#39;s useful to do this because, as we&#39;ll see, the different fingerprint types have very different numbers of bits set for typical molecules. . Here&#39;s the summary of the mean and standard deviation of the number of bits set, from an analysis of 5 million molecules with less than 50 heavy atoms extracted from ZINC: . Fingerprint Type Mean num_bits SD num_bits . Morgan1 | sparse | 29.4 | 5.6 | . Morgan2 | sparse | 48.7 | 9.6 | . Morgan3 | sparse | 66.8 | 13.8 | . FeatMorgan1 | sparse | 20.1 | 3.9 | . FeatMorgan2 | sparse | 38.1 | 7.7 | . FeatMorgan3 | sparse | 56.0 | 11.8 | . RDKit5 | bitvect | 363 | 122 | . RDKit6 | bitvect | 621 | 233 | . RDKit7 | bitvect | 993 | 406 | . pattern | bitvect | 446 | 122 | . avalon | bitvect | 280 | 130 | . atom pairs | sparse | 167 | 56 | . TT | sparse | 33.4 | 9.8 | . atom pairs | bitvect | 267 | 90 | . TT | bitvect | 47.2 | 12.0 | . The bit vector fingerprints were all 4096 bits long. . from rdkit import Chem,DataStructs import time,random,gzip,pickle,copy import numpy as np from collections import Counter,defaultdict from rdkit.Chem import Draw from rdkit.Chem import rdMolDescriptors from rdkit.Avalon import pyAvalonTools from rdkit.Chem.Draw import IPythonConsole from rdkit import DataStructs from rdkit import rdBase %pylab inline print(rdBase.rdkitVersion) import time print(time.asctime()) . Populating the interactive namespace from numpy and matplotlib 2021.09.1pre Tue Jul 6 04:58:28 2021 . /home/glandrum/miniconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: [&#39;copy&#39;, &#39;random&#39;] `%matplotlib` prevents importing * from pylab and numpy &#34; n`%matplotlib` prevents importing * from pylab and numpy&#34; . try: import ipyparallel as ipp rc = ipp.Client() dview = rc[:] dview.execute(&#39;from rdkit import Chem&#39;) dview.execute(&#39;from rdkit import Descriptors&#39;) dview.execute(&#39;from rdkit.Chem import rdMolDescriptors&#39;) dview.execute(&#39;from rdkit.Avalon import pyAvalonTools&#39;) except: print(&quot;could not use ipyparallel&quot;) dview = None . For test data I&#39;ll use the same 16 million ZINC compounds I used in the bit statistics post. . filen=&#39;/scratch/RDKit_git/LocalData/Zinc/zinc_all_clean.pkl.gz&#39; . Loop over the molecules, skip anything with more than 50 atoms, and build fingerprints for all the others. . The fingerprints I generate for this analysis are: . Sparse Morgan with radii 1, 2, and 3 | Sparse FeatureMorgan with radii 1, 2, and 3 | RDKit BitVect with maxPath 5, 6, and 7 | Pattern BitVect | Avalon BitVect | Sparse Atom Pairs | Sparse Topological Torsions | Atom Pair BitVect | Topological Torsion BitVect | . All of the BitVect fingerprints are 4096 bits long . import copy historyf = gzip.open(&#39;../data/fp_bit_counts.history.pkl.gz&#39;,&#39;wb+&#39;) counts=defaultdict(Counter) t1 = time.time() with gzip.open(filen,&#39;rb&#39;) as inf: i = 0 ms = [] while 1: try: m,nm = pickle.load(inf) except EOFError: break if not m or m.GetNumHeavyAtoms()&gt;50: continue ms.append(m) i+=1 if len(ms)&gt;=10000: for v in 1,2,3: cnts = dview.map_sync(lambda x,v=v:len(rdMolDescriptors.GetMorganFingerprint(x,v).GetNonzeroElements()), ms) for obc in cnts: counts[(&#39;Morgan&#39;,v)][obc]+=1 for v in 1,2,3: cnts = dview.map_sync(lambda x,v=v:len(rdMolDescriptors.GetMorganFingerprint(x,v,useFeatures=True).GetNonzeroElements()), ms) for obc in cnts: counts[(&#39;FeatMorgan&#39;,v)][obc]+=1 for v in 5,6,7: cnts = dview.map_sync(lambda x,v=v:Chem.RDKFingerprint(x,maxPath=v,fpSize=4096).GetNumOnBits(), ms) for obc in cnts: counts[(&#39;RDKit&#39;,v)][obc]+=1 cnts = dview.map_sync(lambda x:Chem.PatternFingerprint(x,fpSize=4096).GetNumOnBits(), ms) for obc in cnts: counts[(&#39;pattern&#39;,-1)][obc]+=1 cnts = dview.map_sync(lambda x:pyAvalonTools.GetAvalonFP(x,nBits=4096).GetNumOnBits(), ms) for obc in cnts: counts[(&#39;avalon&#39;,-1)][obc]+=1 cnts = dview.map_sync(lambda x:len(rdMolDescriptors.GetAtomPairFingerprint(x).GetNonzeroElements()), ms) for obc in cnts: counts[(&#39;ap-counts&#39;,-1)][obc]+=1 cnts = dview.map_sync(lambda x:len(rdMolDescriptors.GetTopologicalTorsionFingerprint(x).GetNonzeroElements()), ms) for obc in cnts: counts[(&#39;tt-counts&#39;,-1)][obc]+=1 cnts = dview.map_sync(lambda x:rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(x,nBits=4096).GetNumOnBits(), ms) for obc in cnts: counts[(&#39;ap-bv&#39;,-1)][obc]+=1 cnts = dview.map_sync(lambda x:rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(x,nBits=4096).GetNumOnBits(), ms) for obc in cnts: counts[(&#39;tt-bv&#39;,-1)][obc]+=1 ms = [] if not i%50000: t2 = time.time() print(&quot;Done %d in %.2f sec&quot;%(i,t2-t1)) if not i%500000: pickle.dump(dict(counts),historyf) if i&gt;=5000000: break . Done 50000 in 38.63 sec Done 100000 in 77.02 sec Done 150000 in 115.17 sec Done 200000 in 163.61 sec Done 250000 in 215.39 sec Done 300000 in 267.96 sec Done 350000 in 319.74 sec Done 400000 in 373.11 sec Done 450000 in 415.37 sec Done 500000 in 468.50 sec Done 550000 in 526.23 sec Done 600000 in 570.65 sec Done 650000 in 622.83 sec Done 700000 in 674.11 sec Done 750000 in 724.71 sec Done 800000 in 775.76 sec Done 850000 in 823.44 sec Done 900000 in 873.37 sec Done 950000 in 922.91 sec Done 1000000 in 971.03 sec Done 1050000 in 1019.84 sec Done 1100000 in 1068.24 sec Done 1150000 in 1116.11 sec Done 1200000 in 1164.39 sec Done 1250000 in 1211.31 sec Done 1300000 in 1255.67 sec Done 1350000 in 1306.25 sec Done 1400000 in 1356.04 sec Done 1450000 in 1402.95 sec Done 1500000 in 1453.38 sec Done 1550000 in 1500.31 sec Done 1600000 in 1546.90 sec Done 1650000 in 1593.48 sec Done 1700000 in 1640.38 sec Done 1750000 in 1696.32 sec Done 1800000 in 1750.83 sec Done 1850000 in 1810.42 sec Done 1900000 in 1868.12 sec Done 1950000 in 1926.07 sec Done 2000000 in 1983.37 sec Done 2050000 in 2043.56 sec Done 2100000 in 2102.81 sec Done 2150000 in 2160.67 sec Done 2200000 in 2218.30 sec Done 2250000 in 2272.73 sec Done 2300000 in 2323.77 sec Done 2350000 in 2375.39 sec Done 2400000 in 2427.04 sec Done 2450000 in 2481.36 sec Done 2500000 in 2536.57 sec Done 2550000 in 2591.71 sec Done 2600000 in 2644.06 sec Done 2650000 in 2698.32 sec Done 2700000 in 2752.86 sec Done 2750000 in 2805.41 sec Done 2800000 in 2856.95 sec Done 2850000 in 2909.60 sec Done 2900000 in 2965.05 sec Done 2950000 in 3021.72 sec Done 3000000 in 3073.35 sec Done 3050000 in 3127.90 sec Done 3100000 in 3177.67 sec Done 3150000 in 3234.92 sec Done 3200000 in 3288.20 sec Done 3250000 in 3341.28 sec Done 3300000 in 3393.97 sec Done 3350000 in 3446.92 sec Done 3400000 in 3499.45 sec Done 3450000 in 3549.88 sec Done 3500000 in 3601.67 sec Done 3550000 in 3653.41 sec Done 3600000 in 3705.95 sec Done 3650000 in 3759.37 sec Done 3700000 in 3810.11 sec Done 3750000 in 3861.68 sec Done 3800000 in 3912.28 sec Done 3850000 in 3965.28 sec Done 3900000 in 4022.67 sec Done 3950000 in 4077.32 sec Done 4000000 in 4129.91 sec Done 4050000 in 4185.33 sec Done 4100000 in 4240.67 sec Done 4150000 in 4287.86 sec Done 4200000 in 4340.04 sec Done 4250000 in 4391.57 sec Done 4300000 in 4443.67 sec Done 4350000 in 4493.96 sec Done 4400000 in 4545.53 sec Done 4450000 in 4592.16 sec Done 4500000 in 4640.05 sec Done 4550000 in 4687.30 sec Done 4600000 in 4733.79 sec Done 4650000 in 4780.85 sec Done 4700000 in 4828.29 sec Done 4750000 in 4878.40 sec Done 4800000 in 4927.55 sec Done 4850000 in 4984.36 sec Done 4900000 in 5042.20 sec Done 4950000 in 5101.82 sec Done 5000000 in 5154.32 sec . pickle.dump(dict(counts),gzip.open(&#39;../data/fp_bit_counts.pkl.gz&#39;,&#39;wb+&#39;)) . Now plot the distributions of the number of bits set . morgan_ks = [x for x in counts.keys() if x[0] ==&#39;Morgan&#39;] featmorgan_ks = [x for x in counts.keys() if x[0] ==&#39;FeatMorgan&#39;] rdkit_ks = [x for x in counts.keys() if x[0] == &#39;RDKit&#39;] figure(figsize=(15,15)) pidx=1 subplot(3,3,pidx) for n,r in morgan_ks: cnts = sorted(counts[(n,r)].items()) plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;Morgan&quot;) _=xlabel(&quot;num bits set&quot;) _=ylabel(&quot;count&quot;) _=legend() pidx=2 subplot(3,3,pidx) for n,r in featmorgan_ks: cnts = sorted(counts[(n,r)].items()) plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;FeatMorgan&quot;) _=xlabel(&quot;num bits set&quot;) _=ylabel(&quot;count&quot;) _=legend() pidx=3 subplot(3,3,pidx) for n,r in rdkit_ks: cnts = sorted(counts[(n,r)].items()) plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;RDKit&quot;) _=xlabel(&quot;num bits set&quot;) _=ylabel(&quot;count&quot;) _=legend() for k in counts.keys(): if k[0] in (&#39;Morgan&#39;,&#39;FeatMorgan&#39;,&#39;RDKit&#39;): continue pidx+=1 subplot(3,3,pidx) cnts = sorted(counts[k].items()) plot([x for x,y in cnts],[y for x,y in cnts]) _=title(k[0]) _=xlabel(&quot;num bits set&quot;) _=ylabel(&quot;count&quot;) . The avalon FP curve has an interesting shape . for k,cnts in counts.items(): accum = 0 denom = 0 for cnt,num in cnts.items(): accum += cnt*num denom += num mean = accum/denom dev = 0 for cnt,num in cnts.items(): dev += num*(cnt-mean)**2 dev /= (denom-1) dev = dev**0.5 label = k[0] if k[1]!=-1: label += str(k[1]) print(label,&#39; t%.1f&#39;%mean,&#39;%.1f&#39;%dev) . Morgan1 29.4 5.6 Morgan2 48.7 9.6 Morgan3 66.8 13.8 FeatMorgan1 20.1 3.9 FeatMorgan2 38.1 7.7 FeatMorgan3 56.0 11.8 RDKit5 363.3 122.5 RDKit6 621.7 233.2 RDKit7 993.6 406.3 pattern 445.5 122.5 avalon 279.8 129.9 ap-counts 166.6 56.3 tt-counts 33.4 9.8 ap-bv 267.3 90.0 tt-bv 47.2 12.0 . Convergence . I did 5 million examples, which took a while (about 1.5 hours with 6 worker processes on my PC). Could I have analyzed less and gotten to the same results? Did the means converge? If so, how quickly? . historyf = gzip.open(&#39;../data/fp_bit_counts.history.pkl.gz&#39;,&#39;rb&#39;) means = defaultdict(list) devs = defaultdict(list) nmols = [] while 1: try: lcounts = pickle.load(historyf) except EOFError: break for k,cnts in lcounts.items(): accum = 0 denom = 0 for cnt,num in cnts.items(): accum += cnt*num denom += num mean = accum/denom dev = 0 for cnt,num in cnts.items(): dev += num*(cnt-mean)**2 dev /= (denom-1) dev = dev**0.5 if denom not in nmols: nmols.append(denom) means[k].append(mean) devs[k].append(dev) label = k[0] if k[1]!=-1: label += str(k[1]) print(denom,label,&#39; t%.1f&#39;%mean,&#39;%.1f&#39;%dev) . 500000 Morgan1 26.0 6.2 500000 Morgan2 42.8 10.7 500000 Morgan3 58.7 15.5 500000 FeatMorgan1 18.2 4.3 500000 FeatMorgan2 33.8 8.5 500000 FeatMorgan3 49.5 13.2 500000 RDKit5 324.6 133.9 500000 RDKit6 560.8 256.2 500000 RDKit7 902.9 445.7 500000 pattern 408.8 133.9 500000 avalon 241.8 133.8 500000 ap-counts 133.3 57.6 500000 tt-counts 28.6 10.2 500000 ap-bv 219.5 93.6 500000 tt-bv 41.9 12.9 1000000 Morgan1 27.1 6.1 1000000 Morgan2 44.6 10.5 1000000 Morgan3 61.2 15.2 1000000 FeatMorgan1 18.9 4.2 1000000 FeatMorgan2 35.2 8.4 1000000 FeatMorgan3 51.6 13.0 1000000 RDKit5 340.7 133.9 1000000 RDKit6 588.9 257.4 1000000 RDKit7 948.5 449.9 1000000 pattern 425.2 136.0 1000000 avalon 257.7 136.7 1000000 ap-counts 143.7 57.7 1000000 tt-counts 30.1 10.1 1000000 ap-bv 234.4 92.8 1000000 tt-bv 43.6 12.9 1500000 Morgan1 27.3 5.8 1500000 Morgan2 45.0 9.9 1500000 Morgan3 61.7 14.3 1500000 FeatMorgan1 19.0 4.1 1500000 FeatMorgan2 35.5 8.0 1500000 FeatMorgan3 52.0 12.3 1500000 RDKit5 340.3 127.8 1500000 RDKit6 587.1 246.2 1500000 RDKit7 944.8 432.0 1500000 pattern 424.0 129.4 1500000 avalon 260.5 133.7 1500000 ap-counts 145.1 54.8 1500000 tt-counts 30.5 9.8 1500000 ap-bv 234.9 87.3 1500000 tt-bv 43.7 12.3 2000000 Morgan1 28.0 5.7 2000000 Morgan2 46.2 9.8 2000000 Morgan3 63.4 14.1 2000000 FeatMorgan1 19.4 4.0 2000000 FeatMorgan2 36.3 7.9 2000000 FeatMorgan3 53.3 12.1 2000000 RDKit5 350.7 126.6 2000000 RDKit6 603.5 243.1 2000000 RDKit7 969.0 425.8 2000000 pattern 433.3 128.0 2000000 avalon 269.5 133.1 2000000 ap-counts 152.4 55.5 2000000 tt-counts 31.5 9.8 2000000 ap-bv 245.8 88.2 2000000 tt-bv 45.0 12.2 2500000 Morgan1 28.7 5.8 2500000 Morgan2 47.5 9.8 2500000 Morgan3 65.3 14.2 2500000 FeatMorgan1 19.7 4.0 2500000 FeatMorgan2 37.2 7.9 2500000 FeatMorgan3 54.7 12.1 2500000 RDKit5 361.5 126.3 2500000 RDKit6 621.2 241.1 2500000 RDKit7 996.0 420.5 2500000 pattern 443.2 126.4 2500000 avalon 278.4 132.6 2500000 ap-counts 160.1 56.9 2500000 tt-counts 32.6 9.9 2500000 ap-bv 257.9 90.2 2500000 tt-bv 46.3 12.2 3000000 Morgan1 29.1 5.7 3000000 Morgan2 48.1 9.8 3000000 Morgan3 66.1 14.1 3000000 FeatMorgan1 19.9 3.9 3000000 FeatMorgan2 37.6 7.8 3000000 FeatMorgan3 55.3 12.0 3000000 RDKit5 364.5 124.5 3000000 RDKit6 625.3 237.2 3000000 RDKit7 1001.4 413.2 3000000 pattern 446.5 124.1 3000000 avalon 280.5 131.5 3000000 ap-counts 163.7 57.0 3000000 tt-counts 33.1 9.8 3000000 ap-bv 263.5 90.5 3000000 tt-bv 46.9 12.1 3500000 Morgan1 29.2 5.7 3500000 Morgan2 48.3 9.7 3500000 Morgan3 66.4 14.0 3500000 FeatMorgan1 19.9 3.9 3500000 FeatMorgan2 37.7 7.8 3500000 FeatMorgan3 55.6 11.9 3500000 RDKit5 365.3 123.8 3500000 RDKit6 626.7 236.0 3500000 RDKit7 1003.7 411.3 3500000 pattern 448.4 123.3 3500000 avalon 280.3 131.1 3500000 ap-counts 165.1 56.7 3500000 tt-counts 33.3 9.8 3500000 ap-bv 265.9 90.1 3500000 tt-bv 47.2 12.1 4000000 Morgan1 29.4 5.7 4000000 Morgan2 48.6 9.8 4000000 Morgan3 66.7 14.1 4000000 FeatMorgan1 20.0 3.9 4000000 FeatMorgan2 38.0 7.8 4000000 FeatMorgan3 55.9 12.0 4000000 RDKit5 365.2 124.1 4000000 RDKit6 627.1 236.6 4000000 RDKit7 1005.0 412.4 4000000 pattern 448.6 124.0 4000000 avalon 281.4 131.3 4000000 ap-counts 165.7 56.9 4000000 tt-counts 33.4 9.9 4000000 ap-bv 266.8 90.6 4000000 tt-bv 47.3 12.2 4500000 Morgan1 29.4 5.6 4500000 Morgan2 48.7 9.6 4500000 Morgan3 66.8 13.9 4500000 FeatMorgan1 20.1 3.9 4500000 FeatMorgan2 38.0 7.7 4500000 FeatMorgan3 55.9 11.8 4500000 RDKit5 364.3 123.1 4500000 RDKit6 624.4 234.6 4500000 RDKit7 999.1 408.8 4500000 pattern 447.0 122.7 4500000 avalon 280.7 130.6 4500000 ap-counts 166.3 56.4 4500000 tt-counts 33.4 9.8 4500000 ap-bv 267.3 89.9 4500000 tt-bv 47.3 12.1 5000000 Morgan1 29.4 5.6 5000000 Morgan2 48.7 9.6 5000000 Morgan3 66.8 13.8 5000000 FeatMorgan1 20.1 3.9 5000000 FeatMorgan2 38.1 7.7 5000000 FeatMorgan3 56.0 11.8 5000000 RDKit5 363.3 122.5 5000000 RDKit6 621.7 233.2 5000000 RDKit7 993.6 406.3 5000000 pattern 445.5 122.5 5000000 avalon 279.8 129.9 5000000 ap-counts 166.6 56.3 5000000 tt-counts 33.4 9.8 5000000 ap-bv 267.3 90.0 5000000 tt-bv 47.2 12.0 . Let&#39;s look at those graphically: . morgan_ks = [x for x in counts.keys() if x[0] ==&#39;Morgan&#39;] featmorgan_ks = [x for x in counts.keys() if x[0] ==&#39;FeatMorgan&#39;] rdkit_ks = [x for x in counts.keys() if x[0] == &#39;RDKit&#39;] figure(figsize=(15,15)) nmols2 = [x/1000000 for x in nmols] pidx=1 subplot(3,3,pidx) for n,r in morgan_ks: lmeans = means[(n,r)] ldevs = devs[(n,r)] errorbar(nmols2,lmeans,yerr=ldevs,capsize=3) _=title(&quot;Morgan&quot;) _=xlabel(&quot;num mols (millions)&quot;) _=ylabel(&quot;count&quot;) #_=legend() pidx=2 subplot(3,3,pidx) for n,r in featmorgan_ks: lmeans = means[(n,r)] ldevs = devs[(n,r)] errorbar(nmols2,lmeans,yerr=ldevs,capsize=3) _=title(&quot;FeatMorgan&quot;) _=xlabel(&quot;num mols (millions)&quot;) _=ylabel(&quot;count&quot;) #_=legend() pidx=3 subplot(3,3,pidx) for n,r in rdkit_ks: lmeans = means[(n,r)] ldevs = devs[(n,r)] errorbar(nmols2,lmeans,yerr=ldevs,capsize=3) _=title(&quot;RDKit&quot;) _=xlabel(&quot;num mols (millions)&quot;) _=ylabel(&quot;count&quot;) #_=legend() for k in counts.keys(): if k[0] in (&#39;Morgan&#39;,&#39;FeatMorgan&#39;,&#39;RDKit&#39;): continue pidx+=1 subplot(3,3,pidx) lmeans = means[k] ldevs = devs[k] errorbar(nmols2,lmeans,yerr=ldevs,capsize=3) _=title(k[0]) _=xlabel(&quot;num mols (millions)&quot;) _=ylabel(&quot;count&quot;) . Looks like we would have been fine with 3 million molecules. .",
            "url": "https://greglandrum.github.io/rdkit-blog/fingerprints/reference/2021/07/06/number-of-fp-bits-set.html",
            "relUrl": "/fingerprints/reference/2021/07/06/number-of-fp-bits-set.html",
            "date": " • Jul 6, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Some observations about similarity search thresholds",
            "content": "Updated 08.06.2021 after I expanded the set of “related compounds”. The source of the previous version of the post is available in github. The updates didn’t change the discussion that much. . TL;DR . Based on the analysis here it looks like the fingerprint the RDKit provides which does the best job of efficiently retrieving chemically similar structures is the RDKit fingerprint with maxPath set to 6. . Intro / Results . I recently did a post presenting an approach for finding reasonable thresholds for similarity searches using the fingerprints the RDKit provides. This is a followup to that one written after I’ve done some more looking at the data. I want to come up with a suggestion for which fingerprint to use for similarity searches when the goal is retrieving as many chemically related compounds as possible. I’ll do that by looking at search efficiency as measured by the fraction of the total database retrieved when using similarity thresholds sufficient to return 90-95% of the related compounds. See the earlier post for an explanation of what “related compounds” means here and how the searches were done. . As a reminder, this is how I presented the results in that post and how to interpret the data: . 0.95 of related compounds 0.9 of related compounds 0.8 of related compounds 0.5 of related compounds . Fingerprint 0.95 noise level threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million . Morgan2 (bits) | 0.27 | 0.4 | 0.00019 / 190 | 0.4 | 0.00019 / 190 | 0.45 | 0.00012 / 115 | 0.55 | 2.5e-05 / 25 | . The 0.95 noise level (from the previous analysis) for the MFP2 fingerprint is 0.27. If I want to retrieve 95% of the related compounds I need to set the similarity threshold to 0.4. With this threshold I would retrieve ~190 compounds per million compounds in the database (0.4% of the database). Similarly, if I were willing to live with finding 50% of the related actives I could set the search threshold to 0.55, in which case I’d only retrieve ~25 rows per million compounds in the database. . I won’t reproduce the full results table from the post here, but here are the rows with the highest search efficiencies (lowest number of compounds returned from the “background database”) at 90% and 95% of related compounds found. I sorted the table by the efficiency at 90% of related compounds retrieved: . 0.95 of related compounds 0.9 of related compounds 0.8 of related compounds 0.5 of related compounds . Fingerprint 0.95 noise level threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million . RDKit 7 (bits) | 0.43 | 0.55 | 0.00051 / 510 | 0.6 | 8e-05 / 80 | 0.6 | 8e-05 / 80 | 0.7 | 3e-05 / 30 | . Topological Torsions (counts) | 0.19 | 0.35 | 0.00049 / 489 | 0.4 | 0.00011 / 110 | 0.45 | 7.5e-05 / 75 | 0.55 | 2.5e-05 / 25 | . linear RDKit 7 (bits) | 0.26 | 0.45 | 0.00053 / 535 | 0.5 | 0.00013 / 130 | 0.55 | 9e-05 / 90 | 0.65 | 3.5e-05 / 35 | . RDKit 6 (bits) | 0.31 | 0.5 | 0.00021 / 210 | 0.55 | 0.00014 / 135 | 0.6 | 6e-05 / 60 | 0.7 | 3e-05 / 30 | . Morgan2 (counts) | 0.25 | 0.4 | 0.00014 / 140 | 0.4 | 0.00014 / 140 | 0.45 | 8.5e-05 / 84 | 0.55 | 2e-05 / 20 | . Avalon 1024 (bits) | 0.37 | 0.55 | 0.00075 / 750 | 0.6 | 0.00014 / 140 | 0.65 | 9e-05 / 90 | 0.75 | 2.5e-05 / 25 | . Morgan3 (counts) | 0.20 | 0.3 | 0.00026 / 260 | 0.35 | 0.00015 / 154 | 0.35 | 0.00015 / 154 | 0.45 | 3.5e-05 / 35 | . RDKit 5 (bits) | 0.29 | 0.5 | 0.00025 / 250 | 0.55 | 0.00016 / 155 | 0.6 | 6e-05 / 60 | 0.7 | 3e-05 / 30 | . Topological Torsions (bits) | 0.22 | 0.4 | 0.00016 / 160 | 0.4 | 0.00016 / 160 | 0.45 | 0.00011 / 105 | 0.55 | 3.5e-05 / 35 | . Morgan2 (bits) | 0.27 | 0.4 | 0.00019 / 190 | 0.4 | 0.00019 / 190 | 0.45 | 0.00012 / 115 | 0.55 | 2.5e-05 / 25 | . FeatMorgan3 (counts) | 0.28 | 0.4 | 0.00022 / 220 | 0.4 | 0.00022 / 220 | 0.45 | 0.00013 / 130 | 0.55 | 3e-05 / 30 | . linear RDKit 6 (bits) | 0.28 | 0.5 | 0.00022 / 220 | 0.5 | 0.00022 / 220 | 0.55 | 0.00014 / 140 | 0.7 | 3e-05 / 30 | . The threshold values are rounded to the nearest 0.05. . I’ve included count-based fingerprints in the above table, but they wouldn’t be my first choice for use in a real-world similarity search application. Calculating similarity for count-based fingerprints is significantly slower than bit vector fingerprints, so they really aren’t practical for large datasets. Note that the RDKit has a method for approximating counts using bit vector fingerprints which is used by the Atom Pair and Topological Torsion fingeprints and could also be an option for the other fingerprint types, but that’s a topic for another post. . Based on these numbers (and, of course, the dataset I used) it looks like the RDKit fingerprint is the optimal choice for chemical similarity search. Taking the efficiency at both 90% and 95% into account, the version of the fingerprint with maxPath=6 is arguably better than the version with maxPath=7 (which is the default). There’s not a publication for the RDKit fingerprint but it is described in detail in the RDKit documentation. . The Morgan3 fingerprint, which is what I kind of expected to be the best at this task, doesn’t do that well - the bit-vector based form didn’t even make this list of top performaers. The Morgan2 fingerprint, on the other hand, seems like another good choice. The Morgan fingerprints are the RDKit’s implementation of the circular fingerprints described in this publication. . A real surprise to me was how well the topological torsions fingerprint does at this chemical search. I had (I guess without much evidence) thought of it as more of a fuzzy (or “scaffold-hopping”) fingerprint, but the high efficiency on this chemical search problem makes me reconsider that. Topological torsions were introduced in this publication. . The Avalon fingerprint seems to be another decent choice, at least at 90%. This isn’t surprising to me, but I’ll probably remain resistant to making heavy of it due to the complexity of the fingerprint itself. The only non-code description I’m aware of for the Avalon FP is in the supplementary material for this paper; it’s likely that the current version of the fingerprint, which was under active development for at least 10 years after that paper appeared, deviates from that. . Before getting any deeper into details with this kind of analysis, I think I would like to look into using more than 10K of the “related” molecules and increasing the size of the background database just to make sure the statistics are solid. I’ll do that in a separate post and leave the count-based fingerprints out. .",
            "url": "https://greglandrum.github.io/rdkit-blog/similarity/reference/2021/05/26/similarity-threshold-observations1.html",
            "relUrl": "/similarity/reference/2021/05/26/similarity-threshold-observations1.html",
            "date": " • May 26, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Fingerprint similarity thresholds for database searches",
            "content": "Updated 08.06.2021 after I expanded the set of “related compounds”. The source of the previous version of the post is available in github . Prologue . If you’re interested in this topic and have questions, notice mistakes in my analysis, or have suggestions or ideas for improving this (particularly when it comes to the sets of “related compounds” I use), please either send me email or leave a comment. . Intro / Results . One of the RDKit blog posts I refer back to the most is the one where I tried to establish the Tanimoto similarity value which constitutes a “noise level” for each of the fingerprints the RDKit supports by looking at the distributions of similarities between randomly chosen molecules. I periodically update the post just in case the threshold values change with RDKit versions. Here’s the most recent version of the post and the associated jupyter notebook. I find it really useful to be able to say things like “The 95% noise level for Tanimoto similarity calculated with the the bit-based version of the RDKit’s MFP2 is 0.27.” Based on this I know that when doing similarity searches the threshold for MFP2 shouldn’t be set below 0.27 (I normally say 0.3) in most cases. But that analysis doesn’t tell me what I should set the threshold to. . Of course the answer to that question is “it depends”. Let’s assume that the database you’re searching contains a certain number of compounds which would actually be interesting for you and a much larger number of compounds which are not interesting (at least not for the search you’re currently running). And let’s further assume that the similarities between those interesting compounds and your query is generally above the noise level for the fingerprint you’re using. Any similarity search is going to return a mix of both interesting and non-interesting compounds and the proportions in that mix are generally going to be determined by the similarity threshould you use. Setting the similarity threshold high tends to give a larger proportion of interesting compounds at the cost of missing interesting compounds while a lower threshold will return more of the interesting compounds but a higher fraction of uninteresting compounds. . Basically how bad your FOMO is will determine how many results you need to look through. . This isn’t a big deal if you’re searching a small database and or if you’re going to be post-processing the results using some other computational tool, but if the idea is that you’re going to actually be looking at the results of the similarity search, then result sets with 10K or more rows are going to require a lot of patience. . This post is an attempt to come up with recommendations for reasonable threshold values for the common RDKit fingerprints so that you can make a more informed decision about what to use for a given search. . There’s a more complete description below along with links to the jupyter notebooks with the actual code, but here’s a quick summary of what I did: . I started with 1047 groups of related compounds (~66K compounds in all). Each group is a set of 50-100 compounds from a single ChEMBL document. | I calculated intra-group similarities within each of those 1047 groups using each of the fingerprint types to determine thresholds for retrieving various fractions of each group. | I used a randomly selected subset of 10K of those compounds to do similarity searches on 100K molecules randomly selected from ChEMBL in order to determine what fraction of the database would be retrieved for various similarity thresholds. | Here are what the results look like for bit-based MFP2: . 0.95 of related compounds 0.9 of related compounds 0.8 of related compounds 0.5 of related compounds . Fingerprint 0.95 noise level threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million . Morgan2 (bits) | 0.27 | 0.4 | 0.00019 / 190 | 0.4 | 0.00019 / 190 | 0.45 | 0.00012 / 115 | 0.55 | 2.5e-05 / 25 | . The 0.95 noise level (from the previous analysis) for this FP is 0.27. If I want to retrieve 95% of the related compounds I need to set the similarity threshold to 0.4. With this threshold I would retrieve ~190 compounds per million compounds in the database (0.4% of the database). Similarly, if I were willing to live with finding 50% of the related actives I could set the search threshold to 0.55, in which case I’d only retrieve ~25 rows per million compounds in the database. . I find this is a useful way of thinking about the thresholds: it makes the balance between recall (number of interesting compounds retrieved) and the overall result set size visible. For example, for the MFP2 results shown above, if I’m willing to live with retrieving about 90% of the interesting compounds instead of 95% I would only have to look through about 1/8th of the results from the database. . With that explained, here’s the full results table: . 0.95 of related compounds 0.9 of related compounds 0.8 of related compounds 0.5 of related compounds . Fingerprint 0.95 noise level threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million . MACCS | 0.57 | 0.65 | 0.016 / 15820 | 0.65 | 0.016 / 15820 | 0.7 | 0.0019 / 1880 | 0.8 | 8e-05 / 80 | . Morgan0 (counts) | 0.57 | 0.6 | 0.017 / 16990 | 0.6 | 0.017 / 16990 | 0.65 | 0.009 / 9040 | 0.75 | 0.00057 / 565 | . Morgan1 (counts) | 0.36 | 0.5 | 0.0003 / 300 | 0.5 | 0.0003 / 300 | 0.55 | 0.00017 / 170 | 0.65 | 2.5e-05 / 25 | . Morgan2 (counts) | 0.25 | 0.4 | 0.00014 / 140 | 0.4 | 0.00014 / 140 | 0.45 | 8.5e-05 / 84 | 0.55 | 2e-05 / 20 | . Morgan3 (counts) | 0.20 | 0.3 | 0.00026 / 260 | 0.35 | 0.00015 / 154 | 0.35 | 0.00015 / 154 | 0.45 | 3.5e-05 / 35 | . Morgan0 (bits) | 0.57 | 0.6 | 0.019 / 18550 | 0.6 | 0.019 / 18550 | 0.65 | 0.0099 / 9880 | 0.75 | 0.00063 / 629 | . Morgan1 (bits) | 0.37 | 0.5 | 0.00036 / 360 | 0.5 | 0.00036 / 360 | 0.55 | 0.0002 / 200 | 0.65 | 2.5e-05 / 25 | . Morgan2 (bits) | 0.27 | 0.4 | 0.00019 / 190 | 0.4 | 0.00019 / 190 | 0.45 | 0.00012 / 115 | 0.55 | 2.5e-05 / 25 | . Morgan3 (bits) | 0.22 | 0.3 | 0.00057 / 570 | 0.35 | 0.00031 / 309 | 0.4 | 5e-05 / 50 | 0.5 | 2e-05 / 20 | . FeatMorgan0 (counts) | 0.74 | 0.65 | 0.17 / 165672 | 0.7 | 0.073 / 72975 | 0.7 | 0.073 / 72975 | 0.8 | 0.0086 / 8620 | . FeatMorgan1 (counts) | 0.51 | 0.55 | 0.021 / 21000 | 0.6 | 0.0024 / 2360 | 0.65 | 0.0012 / 1235 | 0.7 | 0.00011 / 110 | . FeatMorgan2 (counts) | 0.36 | 0.45 | 0.0038 / 3782 | 0.5 | 0.00023 / 230 | 0.55 | 0.00014 / 135 | 0.65 | 2.5e-05 / 25 | . FeatMorgan3 (counts) | 0.28 | 0.4 | 0.00022 / 220 | 0.4 | 0.00022 / 220 | 0.45 | 0.00013 / 130 | 0.55 | 3e-05 / 30 | . FeatMorgan0 (bits) | 0.74 | 0.65 | 0.17 / 165672 | 0.7 | 0.073 / 72975 | 0.7 | 0.073 / 72975 | 0.8 | 0.0086 / 8620 | . FeatMorgan1 (bits) | 0.51 | 0.55 | 0.023 / 22962 | 0.6 | 0.0027 / 2660 | 0.65 | 0.0014 / 1390 | 0.7 | 0.00012 / 120 | . FeatMorgan2 (bits) | 0.38 | 0.45 | 0.006 / 6007 | 0.5 | 0.00031 / 310 | 0.55 | 0.00018 / 175 | 0.65 | 2.5e-05 / 25 | . FeatMorgan3 (bits) | 0.30 | 0.4 | 0.00037 / 370 | 0.45 | 0.00021 / 210 | 0.45 | 0.00021 / 210 | 0.55 | 3.5e-05 / 35 | . RDKit 4 (bits) | 0.33 | 0.5 | 0.00069 / 690 | 0.55 | 0.0004 / 400 | 0.6 | 0.00011 / 110 | 0.7 | 4e-05 / 40 | . RDKit 5 (bits) | 0.29 | 0.5 | 0.00025 / 250 | 0.55 | 0.00016 / 155 | 0.6 | 6e-05 / 60 | 0.7 | 3e-05 / 30 | . RDKit 6 (bits) | 0.31 | 0.5 | 0.00021 / 210 | 0.55 | 0.00014 / 135 | 0.6 | 6e-05 / 60 | 0.7 | 3e-05 / 30 | . RDKit 7 (bits) | 0.43 | 0.55 | 0.00051 / 510 | 0.6 | 8e-05 / 80 | 0.6 | 8e-05 / 80 | 0.7 | 3e-05 / 30 | . linear RDKit 4 (bits) | 0.35 | 0.5 | 0.0015 / 1470 | 0.55 | 0.00083 / 830 | 0.6 | 0.00019 / 190 | 0.7 | 5e-05 / 50 | . linear RDKit 5 (bits) | 0.31 | 0.5 | 0.00046 / 455 | 0.55 | 0.00027 / 272 | 0.6 | 9e-05 / 90 | 0.7 | 3e-05 / 30 | . linear RDKit 6 (bits) | 0.28 | 0.5 | 0.00022 / 220 | 0.5 | 0.00022 / 220 | 0.55 | 0.00014 / 140 | 0.7 | 3e-05 / 30 | . linear RDKit 7 (bits) | 0.26 | 0.45 | 0.00053 / 535 | 0.5 | 0.00013 / 130 | 0.55 | 9e-05 / 90 | 0.65 | 3.5e-05 / 35 | . Atom Pairs (counts) | 0.27 | 0.35 | 0.0037 / 3724 | 0.35 | 0.0037 / 3724 | 0.4 | 0.00016 / 160 | 0.5 | 3e-05 / 30 | . Topological Torsions (counts) | 0.19 | 0.35 | 0.00049 / 489 | 0.4 | 0.00011 / 110 | 0.45 | 7.5e-05 / 75 | 0.55 | 2.5e-05 / 25 | . Atom Pairs (bits) | 0.36 | 0.4 | 0.01 / 10380 | 0.45 | 0.0053 / 5250 | 0.5 | 0.00012 / 120 | 0.55 | 7e-05 / 70 | . Topological Torsions (bits) | 0.22 | 0.4 | 0.00016 / 160 | 0.4 | 0.00016 / 160 | 0.45 | 0.00011 / 105 | 0.55 | 3.5e-05 / 35 | . Avalon 512 (bits) | 0.51 | 0.65 | 0.0004 / 400 | 0.65 | 0.0004 / 400 | 0.7 | 8e-05 / 80 | 0.8 | 2e-05 / 20 | . Avalon 1024 (bits) | 0.37 | 0.55 | 0.00075 / 750 | 0.6 | 0.00014 / 140 | 0.65 | 9e-05 / 90 | 0.75 | 2.5e-05 / 25 | . Avalon 512 (counts) | 0.42 | 0.55 | 0.0028 / 2785 | 0.6 | 0.00028 / 280 | 0.65 | 0.00016 / 160 | 0.75 | 2.5e-05 / 25 | . Avalon 1024 (counts) | 0.38 | 0.55 | 0.0012 / 1192 | 0.6 | 0.00017 / 170 | 0.6 | 0.00017 / 170 | 0.7 | 4e-05 / 40 | . The threshold values are rounded to the nearest 0.05. . Method . I won’t get into heavy detail here, the actual notebooks are linked below. . Similarity between random molecules . The workflow and dataset for this is described in a blog post. The very quick summary is that I generated statistics for the similarity distribution of 25K random pairs of reasonable sized (MW&lt;600) molecules exported from ChEMBL. . Groups of related compounds . This is really the central pillar of the post: how do we pick sets of compounds we can use to quantify similarity search performance? . One obvious possibility is to just take groups of molecules which are known to be active against the same targets. This is the classic similarity-based virtual screening use case and it’s one which has been done a lot in the literature. That’s an interesting (and important) use case and it’s something which I may come back to in a future post, but it requires a connection between chemical similarity and biological activity. That connection (or lack thereof) makes analysis of the threshold results more complex and introduces a significant amount of variability. . Here I want to look at a different use case: searching a database and retrieving compounds which are chemically similar to each other. For this I need to pick groups of chemically similar compounds without actually using a traditional approach to chemical similarity. The approach I used is to assume that the typical medicinal chemistry SAR paper includes a bunch of compounds which come from a small number of chemical series (typically one). These compounds are definitely related to each other and it’s not unreasonable to expect that a similarity search for one should return the others as results. . This led me back to an earlier blog post looking at identifying scaffolds from ChEMBL compounds tested in the same assay (given the structure of ChEMBL, this implies that the compounds are from the same paper). That post includes some pre-filtering of the results to try and get only SAR papers by only keeping assays (papers) where 50-100 compounds were measured. For this post I re-ran that analysis against ChEMBL28 and expanded my search criteria to include IC50 data as well as the Ki data used in the original set. The analysis produced results for 1396 groups (a group is the compounds tested in one assay); for this analysis I further filtered these down to the 1047 groups (70026 compounds in total) where the number of atoms in the scaffold is at least 50% of the average number of atoms for compounds in the group. I further filtered each group to only include compounds which have a substructure match to the fuzzy MCS which was found for the full set. The hope here is that this will limit us to only consider the compounds which are part of the chemical series being reported. This lowers the total number of compounds to 66577 across the 1047 groups. . So given these 1047 groups of chemically related compounds I was ready to start doing some searches. . Determining background retrieval rates . In order to get a sense of how many compounds would be retrieved from a database when using the related compounds, I randomly picked 100K molecules from ChEMBL28 to use as a background. I wanted a representative sample, so I didn’t apply MW filters when doing this selection. . I then queried the background compounds with each molecule in a random subset of the 66K members of the “related compounds” set, counted the number of results each returned for each fingerprint/similarity threshold combination, and did statistics based on those results. . Summarizing the data . Here’s an example of a graphical summary of the results presented in the final notebook listed below: . . The violin plots show the distribution of similarity values required to match 50% of the related compound pairs for each of the fingerprints. The dark gray boxes show the noise level for the fingerprints. The red line shows the median fraction of the 100K ChEMBL compounds retrieved when using the median value from the violin plots as a similarity threshold. . The notebooks . Here are the github links for the notebooks I used: . Similarity between random molecules (this is the previous analysis): https://github.com/greglandrum/rdkit_blog/blob/master/notebooks/Fingerprint%20Thresholds.ipynb | Finding scaffolds for ChEMBL documents with Ki values (also a previous analysis): https://github.com/greglandrum/rdkit_blog/blob/master/notebooks/Finding%20Scaffolds%20Revisited%20again.ipynb | Similarity distributions for related compounds: https://github.com/greglandrum/rdkit_blog/blob/master/notebooks/Fingerprint%20Thresholds%20Scaffolds.ipynb Note that this is a new one and I’m still working on cleaning it up and adding more text/explanation | Fraction of the database retrieved when searching (this one also has the calculation of the summary results presented here): https://github.com/greglandrum/rdkit_blog/blob/master/notebooks/Fingerprint%20Thresholds%20Database%20Fraction.ipynb Note that this is a new one and I’m still working on cleaning it up and adding more text/explanation | .",
            "url": "https://greglandrum.github.io/rdkit-blog/similarity/reference/2021/05/21/similarity-search-thresholds.html",
            "relUrl": "/similarity/reference/2021/05/21/similarity-search-thresholds.html",
            "date": " • May 21, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Thresholds for "random" in fingerprints the RDKit supports",
            "content": "This is an updated version of a post. The original version of the notebook can be found in github. . A frequent question that comes up when considering fingerprint similarity is: &quot;What threshold should I use to determine what a neighbor is?&quot; The answer is poorly defined. Of course it depends heavily on the details of the fingerprint, but there&#39;s also a very subjective component: you want to pick a low enough threshold that you&#39;re sure you won&#39;t miss anything, but you don&#39;t want to pick up too much noise. . The goal here is to systematically come up with some guidelines that can be used for fingerprints supported within the RDKit. We will do that by looking a similarities between random &quot;drug-like&quot; (MW&lt;600) molecules picked from ChEMBL. . For the analysis, the 25K similarity values are sorted and the values at particular threshold are examined. . There&#39;s a fair amount of code and results below, so here&#39;s the summary table. To help interpret this: 22500 of the 25000 pairs (90%) have a MACCS keys similarity value less than 0.528. . FingerprintMetric70% level80% level90% level95% level99% level . MACCS | Tanimoto | 0.431 | 0.471 | 0.528 | 0.575 | 0.655 | . Morgan0 (counts) | Tanimoto | 0.429 | 0.471 | 0.525 | 0.568 | 0.651 | . Morgan1 (counts) | Tanimoto | 0.265 | 0.293 | 0.333 | 0.364 | 0.429 | . Morgan2 (counts) | Tanimoto | 0.181 | 0.201 | 0.229 | 0.252 | 0.305 | . Morgan3 (counts) | Tanimoto | 0.141 | 0.156 | 0.178 | 0.196 | 0.238 | . Morgan0 (bits) | Tanimoto | 0.435 | 0.475 | 0.529 | 0.571 | 0.656 | . Morgan1 (bits) | Tanimoto | 0.273 | 0.301 | 0.341 | 0.371 | 0.434 | . Morgan2 (bits) | Tanimoto | 0.197 | 0.217 | 0.246 | 0.269 | 0.322 | . Morgan3 (bits) | Tanimoto | 0.165 | 0.181 | 0.203 | 0.222 | 0.264 | . FeatMorgan0 (counts) | Tanimoto | 0.583 | 0.630 | 0.690 | 0.737 | 0.818 | . FeatMorgan1 (counts) | Tanimoto | 0.390 | 0.425 | 0.474 | 0.511 | 0.581 | . FeatMorgan2 (counts) | Tanimoto | 0.272 | 0.298 | 0.333 | 0.364 | 0.424 | . FeatMorgan3 (counts) | Tanimoto | 0.209 | 0.228 | 0.256 | 0.279 | 0.328 | . FeatMorgan0 (bits) | Tanimoto | 0.583 | 0.630 | 0.690 | 0.737 | 0.818 | . FeatMorgan1 (bits) | Tanimoto | 0.395 | 0.429 | 0.477 | 0.514 | 0.585 | . FeatMorgan2 (bits) | Tanimoto | 0.284 | 0.310 | 0.347 | 0.376 | 0.434 | . FeatMorgan3 (bits) | Tanimoto | 0.228 | 0.248 | 0.276 | 0.299 | 0.349 | . RDKit 4 (bits) | Tanimoto | 0.209 | 0.239 | 0.285 | 0.325 | 0.426 | . RDKit 5 (bits) | Tanimoto | 0.197 | 0.219 | 0.253 | 0.287 | 0.368 | . RDKit 6 (bits) | Tanimoto | 0.230 | 0.250 | 0.280 | 0.308 | 0.369 | . RDKit 7 (bits) | Tanimoto | 0.313 | 0.346 | 0.389 | 0.429 | 0.507 | . linear RDKit 4 (bits) | Tanimoto | 0.225 | 0.258 | 0.309 | 0.354 | 0.462 | . linear RDKit 5 (bits) | Tanimoto | 0.198 | 0.225 | 0.269 | 0.309 | 0.404 | . linear RDKit 6 (bits) | Tanimoto | 0.187 | 0.210 | 0.246 | 0.282 | 0.365 | . linear RDKit 7 (bits) | Tanimoto | 0.182 | 0.203 | 0.234 | 0.264 | 0.337 | . Atom Pairs (counts) | Tanimoto | 0.180 | 0.204 | 0.237 | 0.265 | 0.325 | . Torsions (counts) | Tanimoto | 0.107 | 0.130 | 0.165 | 0.194 | 0.266 | . Atom Pairs (bits) | Tanimoto | 0.275 | 0.301 | 0.335 | 0.363 | 0.415 | . Torsions (bits) | Tanimoto | 0.133 | 0.155 | 0.188 | 0.219 | 0.288 | . Avalon 512 (bits) | Tanimoto | 0.369 | 0.407 | 0.461 | 0.505 | 0.575 | . Avalon 1024 (bits) | Tanimoto | 0.269 | 0.297 | 0.340 | 0.375 | 0.449 | . Avalon 512 (counts) | Tanimoto | 0.300 | 0.333 | 0.379 | 0.418 | 0.491 | . Avalon 1024 (counts) | Tanimoto | 0.267 | 0.299 | 0.344 | 0.384 | 0.462 | . from rdkit import Chem from rdkit.Chem import rdMolDescriptors from rdkit.Avalon import pyAvalonTools from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit import rdBase from rdkit import DataStructs from collections import defaultdict import pickle,random,gzip print(rdBase.rdkitVersion) import time print(time.asctime()) %pylab inline . 2021.03.1 Tue May 18 06:44:23 2021 Populating the interactive namespace from numpy and matplotlib . /home/glandrum/miniconda3/envs/rdkit_blog/lib/python3.9/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: [&#39;random&#39;] `%matplotlib` prevents importing * from pylab and numpy warn(&#34;pylab import has clobbered these variables: %s&#34; % clobbered + . Read in the data . We&#39;re using the set of 25K reference pairs generated in an earlier post: http://rdkit.blogspot.ch/2013/10/building-similarity-comparison-set-goal.html . As a quick reminder: these are pairs of molecules taken from ChEMBL with MW&lt;600 and a count-based MFP0 similarity of at least 0.7 to each other. . ind = [x.split() for x in gzip.open(&#39;../data/chembl16_25K.pairs.txt.gz&#39;)] ms1 = [] ms2 = [] for i,row in enumerate(ind): m1 = Chem.MolFromSmiles(row[1]) ms1.append((row[0],m1)) m2 = Chem.MolFromSmiles(row[3]) ms2.append((row[2],m2)) . Those pairs are related to each other, but we want random pairs, so shuffle the second list: . random.seed(23) random.shuffle(ms2) . try: import ipyparallel as ipp rc = ipp.Client() dview = rc[:] dview.execute(&#39;from rdkit import Chem&#39;) dview.execute(&#39;from rdkit import Descriptors&#39;) dview.execute(&#39;from rdkit.Chem import rdMolDescriptors&#39;) dview.execute(&#39;from rdkit.Avalon import pyAvalonTools&#39;) except: print(&quot;could not use ipyparallel&quot;) dview = None def compareFPs(ms1,ms2,fpfn,fpName): if dview is not None: fps = dview.map_sync(lambda x:fpfn(x[1]),ms1) fp2s = dview.map_sync(lambda x:fpfn(x[1]),ms2) else: fps = [fpfn(x[1]) for x in ms1] fp2s = [fpfn(x[1]) for x in ms2] sims = [DataStructs.TanimotoSimilarity(x,y) for x,y in zip(fps,fp2s)] sl = sorted(sims) np = len(sl) with open(&#39;fp_results.txt&#39;,&#39;a+&#39;) as outf: outf.write(f&#39;&lt;tr&gt;&lt;td&gt;{fpName}&lt;/td&gt;&lt;td&gt;Tanimoto&lt;/td&gt; n&#39;) for bin in (.7,.8,.9,.95,.99): simv = sl[int(bin*np)] print( bin,simv) outf.write(f&#39; &lt;td&gt;{simv:.3f}&lt;/td&gt; n&#39;) outf.write(&#39;&lt;/tr&gt;&#39;) hist(sims,bins=20) xlabel(fpName) . MACCS . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMACCSKeysFingerprint(x),&quot;MACCS&quot;) . 0.7 0.4305555555555556 0.8 0.47058823529411764 0.9 0.5283018867924528 0.95 0.575 0.99 0.6551724137931034 . Morgan FPs . count based . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,0),&quot;Morgan0 (counts)&quot;) . 0.7 0.42857142857142855 0.8 0.47058823529411764 0.9 0.525 0.95 0.5675675675675675 0.99 0.6511627906976745 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,1),&quot;Morgan1 (counts)&quot;) . 0.7 0.2653061224489796 0.8 0.2926829268292683 0.9 0.3333333333333333 0.95 0.36363636363636365 0.99 0.42857142857142855 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,2),&quot;Morgan2 (counts)&quot;) . 0.7 0.18110236220472442 0.8 0.20125786163522014 0.9 0.22916666666666666 0.95 0.2523364485981308 0.99 0.304635761589404 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,3),&quot;Morgan3 (counts)&quot;) . 0.7 0.140625 0.8 0.1557377049180328 0.9 0.17751479289940827 0.95 0.19607843137254902 0.99 0.23841059602649006 . bit-vector based . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,0,1024),&quot;Morgan0 (bits)&quot;) . 0.7 0.43478260869565216 0.8 0.475 0.9 0.5294117647058824 0.95 0.5714285714285714 0.99 0.65625 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,1,1024),&quot;Morgan1 (bits)&quot;) . 0.7 0.2727272727272727 0.8 0.30120481927710846 0.9 0.34065934065934067 0.95 0.37142857142857144 0.99 0.4342105263157895 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,2,1024),&quot;Morgan2 (bits)&quot;) . 0.7 0.19708029197080293 0.8 0.2169811320754717 0.9 0.24603174603174602 0.95 0.2689655172413793 0.99 0.3217391304347826 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,3,1024),&quot;Morgan3 (bits)&quot;) . 0.7 0.16477272727272727 0.8 0.18072289156626506 0.9 0.20261437908496732 0.95 0.2222222222222222 0.99 0.26356589147286824 . FeatMorgan . count based . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,0,useFeatures=True),&quot;FeatMorgan0 (counts)&quot;) . 0.7 0.5833333333333334 0.8 0.6296296296296297 0.9 0.6896551724137931 0.95 0.7368421052631579 0.99 0.8181818181818182 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,1,useFeatures=True),&quot;FeatMorgan1 (counts)&quot;) . 0.7 0.3902439024390244 0.8 0.42528735632183906 0.9 0.47368421052631576 0.95 0.5106382978723404 0.99 0.5813953488372093 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,2,useFeatures=True),&quot;FeatMorgan2 (counts)&quot;) . 0.7 0.272 0.8 0.29770992366412213 0.9 0.3333333333333333 0.95 0.36363636363636365 0.99 0.424 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,3,useFeatures=True),&quot;FeatMorgan3 (counts)&quot;) . 0.7 0.2087378640776699 0.8 0.22818791946308725 0.9 0.2558139534883721 0.95 0.2785714285714286 0.99 0.3275862068965517 . bit vectors . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,0,1024,useFeatures=True),&quot;FeatMorgan0 (bits)&quot;) . 0.7 0.5833333333333334 0.8 0.6296296296296297 0.9 0.6896551724137931 0.95 0.7368421052631579 0.99 0.8181818181818182 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,1,1024,useFeatures=True),&quot;FeatMorgan1 (bits)&quot;) . 0.7 0.39473684210526316 0.8 0.42857142857142855 0.9 0.4772727272727273 0.95 0.5142857142857142 0.99 0.5849056603773585 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,2,1024,useFeatures=True),&quot;FeatMorgan2 (bits)&quot;) . 0.7 0.28368794326241137 0.8 0.30973451327433627 0.9 0.3469387755102041 0.95 0.37606837606837606 0.99 0.43434343434343436 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,3,1024,useFeatures=True),&quot;FeatMorgan3 (bits)&quot;) . 0.7 0.22807017543859648 0.8 0.24770642201834864 0.9 0.27564102564102566 0.95 0.29901960784313725 0.99 0.3488372093023256 . RDKit . Branched (default) . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=4),&quot;RDKit 4 (bits)&quot;) . 0.7 0.2094017094017094 0.8 0.23863636363636365 0.9 0.2849462365591398 0.95 0.3254237288135593 0.99 0.4258373205741627 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=5),&quot;RDKit 5 (bits)&quot;) . 0.7 0.19672131147540983 0.8 0.21875 0.9 0.2534562211981567 0.95 0.28735632183908044 0.99 0.3682170542635659 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=6),&quot;RDKit 6 (bits)&quot;) . 0.7 0.22965641952983726 0.8 0.2502120441051739 0.9 0.28023598820059 0.95 0.30818767249310025 0.99 0.3686382393397524 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=7),&quot;RDKit 7 (bits)&quot;) . 0.7 0.3130372492836676 0.8 0.34558303886925795 0.9 0.38909541511771994 0.95 0.4286600496277916 0.99 0.5068903535050928 . linear . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=4,branchedPaths=False),&quot;linear RDKit 4 (bits)&quot;) . 0.7 0.22456140350877193 0.8 0.25773195876288657 0.9 0.30864197530864196 0.95 0.35403726708074534 0.99 0.46153846153846156 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=5,branchedPaths=False),&quot;linear RDKit 5 (bits)&quot;) . 0.7 0.19756838905775076 0.8 0.22549019607843138 0.9 0.2687224669603524 0.95 0.3090909090909091 0.99 0.40425531914893614 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=6,branchedPaths=False),&quot;linear RDKit 6 (bits)&quot;) . 0.7 0.18657937806873978 0.8 0.21005917159763313 0.9 0.24612403100775193 0.95 0.2820069204152249 0.99 0.36476426799007444 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=7,branchedPaths=False),&quot;linear RDKit 7 (bits)&quot;) . 0.7 0.18204488778054864 0.8 0.20286085825747724 0.9 0.23367198838896952 0.95 0.2640625 0.99 0.33689024390243905 . Atom pairs and torsions . count-based . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetAtomPairFingerprint(x),&quot;Atom Pairs (counts)&quot;) . 0.7 0.17993630573248406 0.8 0.20386266094420602 0.9 0.23671497584541062 0.95 0.26545454545454544 0.99 0.32547169811320753 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetTopologicalTorsionFingerprint(x),&quot;Torsions (counts)&quot;) . 0.7 0.10714285714285714 0.8 0.13 0.9 0.16470588235294117 0.95 0.19387755102040816 0.99 0.26582278481012656 . bit vectors . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(x),&quot;Atom Pairs (bits)&quot;) . 0.7 0.27488151658767773 0.8 0.3008298755186722 0.9 0.3353658536585366 0.95 0.36342042755344417 0.99 0.4146341463414634 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(x),&quot;Torsions (bits)&quot;) . 0.7 0.1326530612244898 0.8 0.1553398058252427 0.9 0.18840579710144928 0.95 0.2191780821917808 0.99 0.2876712328767123 . Avalon . compareFPs(ms1,ms2,lambda x:pyAvalonTools.GetAvalonFP(x,512),&quot;Avalon 512 (bits)&quot;) . 0.7 0.3693379790940767 0.8 0.4074074074074074 0.9 0.46130952380952384 0.95 0.5054347826086957 0.99 0.5749318801089919 . compareFPs(ms1,ms2,lambda x:pyAvalonTools.GetAvalonFP(x,1024),&quot;Avalon 1024 (bits)&quot;) . 0.7 0.26932668329177056 0.8 0.2972972972972973 0.9 0.3402061855670103 0.95 0.3747016706443914 0.99 0.4490909090909091 . Avalon Counts . compareFPs(ms1,ms2,lambda x:pyAvalonTools.GetAvalonCountFP(x,512),&quot;Avalon 512 (counts)&quot;) . 0.7 0.30028063610851263 0.8 0.332624867162593 0.9 0.3787951807228916 0.95 0.4175461741424802 0.99 0.491005291005291 . compareFPs(ms1,ms2,lambda x:pyAvalonTools.GetAvalonCountFP(x,1024),&quot;Avalon 1024 (counts)&quot;) . 0.7 0.26651162790697674 0.8 0.2988505747126437 0.9 0.34438775510204084 0.95 0.3844486589000271 0.99 0.4624173180998196 .",
            "url": "https://greglandrum.github.io/rdkit-blog/fingerprints/similarity/reference/2021/05/18/fingerprint-thresholds1.html",
            "relUrl": "/fingerprints/similarity/reference/2021/05/18/fingerprint-thresholds1.html",
            "date": " • May 18, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Intro to the molecule enumerator",
            "content": "The V3000 mol file format allows a number of interesting and useful advanced query features. Here I&#39;ll look at two of them: position variation bonds (a.k.a. variable attachment points) and link nodes. . This blog post uses features from the 2021.03.1 RDKit release; some of this will not work with older releases. . from rdkit import Chem from rdkit.Chem.Draw import rdDepictor from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdMolEnumerator import rdkit print(rdkit.__version__) . 2021.03.1 . Position variation bonds . Here&#39;s a molecule with a position variation bond: . pv1 = Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2007 06232015292D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 9 8 0 0 0 M V30 BEGIN ATOM M V30 1 C -1.7083 2.415 0 0 M V30 2 C -3.042 1.645 0 0 M V30 3 C -3.042 0.105 0 0 M V30 4 N -1.7083 -0.665 0 0 M V30 5 C -0.3747 0.105 0 0 M V30 6 C -0.3747 1.645 0 0 M V30 7 * -0.8192 1.3883 0 0 M V30 8 O -0.8192 3.6983 0 0 M V30 9 C 0.5145 4.4683 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 7 8 ENDPTS=(3 1 5 6) ATTACH=ANY M V30 8 1 8 9 M V30 END BOND M V30 END CTAB M END&#39;&#39;&#39;) pv1 . The query is describing a molecule consisting of a pyriding ring with an methoxy substituted either ortho, meta, or para to the N atom. . The RDKit includes functionality in the rdkit.Chem.rdMolEnumerator module which allows you enumerate all of the molecules which are described by this query. . The function rdMolEnumerator.Enumerate() is straightforward to use: given a molecule with supported query features it returns a MolBundle object which includes each possible expansion of the query: . pv1_bundle = rdMolEnumerator.Enumerate(pv1) pv1_bundle . &lt;rdkit.Chem.rdchem.MolBundle at 0x7fc138399b20&gt; . We can render the molecules in the bundle using Draw.MolsToGridImage(): . Draw.MolsToGridImage(pv1_bundle) . These are pretty ugly since the enumeration hasn&#39;t generated new coordinates for the atom which correspond to the new connectivity. . I&#39;ll use this convenience function to find the common core shared by the molecules in a bundle and generate 2D coordinates for all the molecules with the core oriented consistently: . from rdkit.Chem import rdFMCS def align_bundle_coords(bndl): ps = rdFMCS.MCSParameters() for m in bndl: Chem.SanitizeMol(m) mcs = rdFMCS.FindMCS(bndl,completeRingsOnly=True) q = Chem.MolFromSmarts(mcs.smartsString) rdDepictor.Compute2DCoords(q) for m in bndl: rdDepictor.GenerateDepictionMatching2DStructure(m,q) . Now let&#39;s apply that to our bundle: . pv1_bundle = rdMolEnumerator.Enumerate(pv1) align_bundle_coords(pv1_bundle) Draw.MolsToGridImage(pv1_bundle) . Of course a molecule can have more than one position variation bond: . pv2 = Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2007 06242006032D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 10 8 0 0 0 M V30 BEGIN ATOM M V30 1 C -1.7083 2.415 0 0 M V30 2 C -3.042 1.645 0 0 M V30 3 C -3.042 0.105 0 0 M V30 4 N -1.7083 -0.665 0 0 M V30 5 C -0.3747 0.105 0 0 M V30 6 C -0.3747 1.645 0 0 M V30 7 * -3.042 0.875 0 0 M V30 8 F -5.0434 0.875 0 0 M V30 9 * -1.0415 2.03 0 0 M V30 10 Cl -1.0415 4.34 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 7 8 ENDPTS=(2 2 3) ATTACH=ANY M V30 8 1 9 10 ENDPTS=(2 1 6) ATTACH=ANY M V30 END BOND M V30 END CTAB M END &#39;&#39;&#39;) pv2 . This is also supported by the enumerator: . pv2_bundle = rdMolEnumerator.Enumerate(pv2) align_bundle_coords(pv2_bundle) Draw.MolsToGridImage(pv2_bundle) . Link nodes . Another useful query feature, link nodes, allow you to describe rings of various sizes or chains with different lengths: . link1 = Chem.MolFromMolBlock(&#39;&#39;&#39;one linknode Mrv2007 06222005102D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 6 6 0 0 0 M V30 BEGIN ATOM M V30 1 C 8.25 12.1847 0 0 M V30 2 C 6.9164 12.9547 0 0 M V30 3 C 6.9164 14.4947 0 0 M V30 4 C 9.5836 14.4947 0 0 M V30 5 C 9.5836 12.9547 0 0 M V30 6 O 8.25 10.6447 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 1 2 3 M V30 3 1 4 5 M V30 4 1 1 5 M V30 5 1 3 4 M V30 6 1 1 6 M V30 END BOND M V30 LINKNODE 1 4 2 1 2 1 5 M V30 END CTAB M END&#39;&#39;&#39;) link1 . And we can enumerate and display these in the same way. Here there&#39;s not much sense in doing the MCS analysis to get the shared coordinates, so I just generate coordinates for the molecules directly: . link1_bundle = rdMolEnumerator.Enumerate(link1) for m in link1_bundle: Chem.SanitizeMol(m) rdDepictor.Compute2DCoords(m) Draw.MolsToGridImage(link1_bundle) . Combining them . We can also combine link nodes and position variation bonds in the same molecule: . combined = Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2108 05132110052D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 19 20 0 0 0 M V30 BEGIN ATOM M V30 1 N -2.2078 4.3165 0 0 M V30 2 C -2.9544 2.9695 0 0 M V30 3 C -2.1612 1.6495 0 0 M V30 4 C -0.6214 1.6763 0 0 M V30 5 C 0.1252 3.0233 0 0 M V30 6 C -0.668 4.3433 0 0 M V30 7 C 1.6649 3.0501 0 0 M V30 8 C -4.4941 2.9427 0 0 M V30 9 C 2.4581 1.7301 0 0 M V30 10 C 2.985 3.8433 0 0 M V30 11 C 3.7781 2.5233 0 0 M V30 12 C -6.3747 4.5774 0 0 M V30 13 C -6.9764 3.1598 0 0 M V30 14 C -5.8142 2.1495 0 0 M V30 15 C -4.8405 4.4431 0 0 M V30 16 F -7.1678 5.8974 0 0 M V30 17 O 3.3575 5.3376 0 0 M V30 18 * -1.1502 2.5564 0 0 M V30 19 C -1.1502 0.2464 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 5 7 M V30 8 1 2 8 M V30 9 1 9 11 M V30 10 1 10 11 M V30 11 1 7 9 M V30 12 1 7 10 M V30 13 1 12 13 M V30 14 1 13 14 M V30 15 1 12 15 M V30 16 1 14 8 M V30 17 1 8 15 M V30 18 1 12 16 M V30 19 1 10 17 M V30 20 1 18 19 ENDPTS=(3 6 3 4) ATTACH=ANY M V30 END BOND M V30 LINKNODE 1 2 2 10 7 10 11 M V30 LINKNODE 1 2 2 12 13 12 15 M V30 END CTAB M END &#39;&#39;&#39;) combined . Enumerating that produces 12 molecules: . combined_bundle = rdMolEnumerator.Enumerate(combined) align_bundle_coords(combined_bundle) Draw.MolsToGridImage(combined_bundle,subImgSize=(300,250)) . Using MolBundles for substructure search . MolBundles can also be used as substructure search queries. . Here&#39;s another query molecule: . qry= Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2108 05132113572D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 13 13 0 0 0 M V30 BEGIN ATOM M V30 1 C 1.2124 -2.4845 0 0 M V30 2 N 2.5461 -3.2545 0 0 M V30 3 C 2.5461 -4.7945 0 0 M V30 4 C 1.2124 -5.5645 0 0 M V30 5 C 1.2124 -7.1045 0 0 M V30 6 C -0.0335 -8.0097 0 0 M V30 7 O 0.4424 -9.4744 0 0 M V30 8 C 1.9824 -9.4744 0 0 M V30 9 C 2.4583 -8.0097 0 0 M V30 10 C -0.1212 -4.7945 0 0 M V30 11 C -0.1212 -3.2545 0 0 M V30 12 * 0.5456 -2.8695 0 0 M V30 13 C -0.6094 -0.869 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 2 1 2 M V30 2 1 2 3 M V30 3 2 3 4 M V30 4 1 4 5 M V30 5 1 6 7 M V30 6 1 7 8 M V30 7 1 8 9 M V30 8 1 5 9 M V30 9 1 4 10 M V30 10 2 10 11 M V30 11 1 1 11 M V30 12 1 12 13 ENDPTS=(2 11 1) ATTACH=ANY M V30 13 1 5 6 M V30 END BOND M V30 LINKNODE 1 2 2 6 5 6 7 M V30 END CTAB M END &#39;&#39;&#39;) qry . And a set of molecules to search through which I pulled from ChEMBL . smis = &#39;&#39;&#39;Cc1nc(C(C)(C)NC(=O)c2ccc(C3CCOCC3)c(OCC3CC3)n2)no1 CC(C)(CO)NC(=O)c1ccc(C2CCOC2)c(OCC2CC2)n1 CC(C)(NC(=O)c1ccc(C2CCOCC2)c(OCC2CC2)n1)c1nccs1 Cc1c(-c2cncc(C3(O)CCOCC3)c2)cnc2c1CCCN2C(N)=O CC(C)Oc1cc(NC(=O)N2CCCc3cc(C4CCOC4)c(C=O)nc32)ncc1C#N NC(=O)N1CCCc2cc(-c3cncc(C4(O)CCOC4)c3)cnc21 CCC(CC)(NC(=O)c1ccc(C2CCOCC2)c(OCC2CC2)n1)C(=O)NC CC(C)(NC(=O)c1ccc(C2CCOCC2)c(OCC2CC2)n1)c1ncco1 N#Cc1cc(-c2ccoc2)c2ccc(OCc3cncc(C4(O)CCOCC4)c3)cc2c1 Nc1cc(-c2cc(C3CCOCC3)cnc2N)ccc1C(=O)N[C@H](CO)c1ccccc1 Nc1ncc(C2CCOCC2)cc1-c1ccc(C(=O)NCc2cccnc2)cc1 Cc1nc(C(C)(C)NC(=O)c2ccc(C3CCOC3)c(OCC3CC3)n2)no1 CC(C)C[C@H](NC(=O)c1ccc(C2CCOC2)c(OCC2CC2)n1)C(N)=O Nc1ncc(C2CCOCC2)cc1-c1ccc(C(=O)N[C@H](CO)c2ccccc2)cc1Cl NC(=O)[C@H](CC1CC1)NC(=O)c1ccc(C2CCOC2)c(OCC2CC2)n1 &#39;&#39;&#39; mols = [Chem.MolFromSmiles(x.strip()) for x in smis.split(&#39; n&#39;) if x.strip()] . The query itself doesn&#39;t match most of these molecules: . matches = [x for x in mols if x.HasSubstructMatch(qry)] len(mols),len(matches) . (15, 6) . But if we enumerate it into a MolBundle and use that as the substructure query then all the molecules match: . qry_bundle = rdMolEnumerator.Enumerate(qry) matches = [x for x in mols if x.HasSubstructMatch(qry_bundle)] len(mols),len(matches) . (15, 15) . Let&#39;s look at a few of those matches . matches = [] matched_ats = [] for x in mols: match = x.GetSubstructMatch(qry_bundle) if match: matches.append(x) matched_ats.append(match) Draw.MolsToGridImage(matches[:6],highlightAtomLists=matched_ats,subImgSize=(300,250)) . We&#39;re working on expanding support for the MolBundle in other RDKit code. For example, it would be really nice to be able to use them directly as queries for the SubstructLibrary . Final bit: input from CXSMILES . It&#39;s also possible to read both variable attachment points and link nodes from CXSMILES: . m = Chem.MolFromSmiles(&#39;CO*.C1=CC=NC=C1 |c:2,4,6,m:2:3.5.4|&#39;) m . As that example shows, the coordinate generation code is currently not great at setting the atom positions for these. That&#39;s a ToDo for a future release. . m = Chem.MolFromSmiles(&#39;OC1CCCC1 |LN:1:1.4.2.5|&#39;) m . The RDKit currently does not write either link nodes or variable attachment points to CXSMILES, that&#39;s another ToDo for a future release. .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/substructure/2021/05/13/intro-to-the-molecule-enumerator.html",
            "relUrl": "/tutorial/substructure/2021/05/13/intro-to-the-molecule-enumerator.html",
            "date": " • May 13, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "A new way to use the RDKit from other languages",
            "content": "TL;DR . We’ve added a new API which makes it easy to use the RDKit from programming languages other than C++, Python, Java or C#. . Intro . The majority of the RDKit is written in C++, but we also make wrappers allowing you to use it from other programming languages. The main one of these, and the most complete, is for Python and is written by hand (using Boost::Python). The Java and C# wrappers are generated more or less automatically using SWIG. . Back in 2019 we decided to do a JavaScript (JS) wrapper which follows a slightly different approach: instead of wrapping the whole toolkit the new JS wrappers provide access to a useful subset of RDKit functionality provided as functions. We called this MinimalLib and there’s more information in an earlier blog post. . We’ve now extended MinimalLib and made it useable from any programming language which supports calling into external libraries written in C (often called using a “C Foreign Function Interface”, or CFFI). Since most common programming languages support CFFI, I think this will help bring chemistry to a bunch of other languages. . How it works . This is easiest explained with an example. Since each programming language implements CFFI slightly differently, and I’m not even close to being good at some of the more intersting ones like go, Rust, or Julia, I’ll demonstrate using C itself and sample code adapted from cffi_test.c, one of the files used to test the new interface. . The general pattern when working with rdkit-cffi is to parse a molecule input format to get back a serialized (“pickled”) form of that molecule and then to pass that pickled molecule to other functions which do the chemistry operations you’re interested in. . Parsing molecule formats and operating on molecules . The “hello world” equivalent in cheminformatics is generating canonical SMILES. Here’s a full C program showing how you do that with rdkit-cffi, I will explain the rdkit-cffi functions and how they are used in more detail below: . #include &lt;stdio.h&gt; #include &lt;string.h&gt; #include &lt;stdlib.h&gt; #include &quot;cffiwrapper.h&quot; void canon_smiles(){ char *pkl; size_t pkl_size; pkl = get_mol(&quot;c1cc(O)ccc1&quot;,&amp;pkl_size,&quot;&quot;); char *smiles=get_smiles(pkl,pkl_size,NULL); printf(&quot;Canonical SMILES: %s n&quot;,smiles); free(smiles); free(pkl); } int main(){ enable_logging(); printf(&quot;hello %s n&quot;,version()); canon_smiles(); return 0; } . I compiled this on my linux machine as follows: . % cc -o demo.exe -I $RDBASE/Code demo.c $RDBASE/lib/librdkitcffi.so . Running it produces: . % ./demo.exe hello 2021.09.1pre Canonical SMILES: Oc1ccccc1 . Let’s look at the rdkit-cffi parts of this, starting with the main() function. . We start by enabling the RDKit’s logging system: . enable_logging(); . If you skip this, you won’t see any of the usual RDKit errors or warnings. . Next we use the version() function to get the version of the RDKit which is being used and then print that out. . With that basic initialization out of the way we call the function canon_smiles(), which is where the real work happens. Here we start by parsing a SMILES using the get_mol() function: . pkl = get_mol(&quot;c1cc(O)ccc1&quot;,&amp;pkl_size,&quot;&quot;); . get_mol() returns a binary string with the pickled representation of the molecule and uses the pkl_size argument (an integer) to return the length of that string (this is an unfortunately necessary implementation detail). The final argument to get_mol(), the empty string, can be used to pass in an JSON string containing additional arguments controlling the parsing (we could have also passed this argument as NULL). get_mol() currently supports constructing molecules from SMILES (and CXSMILES), Mol/SDF, and the RDKit’s JSON format; it recognized automatically which parser should be used. We will be expanding the list of supported formats in the future. . After we have the molecule processed we can get the canonical SMILES for it by calling the get_smiles() function: . char *smiles=get_smiles(pkl,pkl_size,NULL); . get_smiles() follows the general pattern for rdkit-cffi functions which operate on molecules: the first two arguments are the pickled molecule and the length of the pickle string, the third argument is a JSON string with additional options to be used when generating the SMILES; in this case we want the defaults, so we pass a NULL pointer (we could also have used the empty string &quot;&quot;). . Finally, and not to be overlooked when working in C, we need to free the memory which was allocated to hold the molecule pickle and the SMILES: . free(smiles); free(pkl); . The functions which are available are declared in cffiwrapper.h. . Modifying molecules . Some rdkit-cffi functions modify the molecule. In this case the general pattern is the modify the molecule in place, i.e. to modify the current molecule instead of returning a new one. . Here’s a simple function which parses a SMILES, add Hs to the molecule, generates a 3D conformer using a fixed random seed, and then prints out the molblock for the modified molecule: . void generate_conformer(){ char *pkl; size_t pkl_size; pkl = get_mol(&quot;c1cc(O)ccc1&quot;,&amp;pkl_size,NULL); add_hs(&amp;pkl,&amp;pkl_size); set_3d_coords(&amp;pkl,&amp;pkl_size,&quot;{ &quot;randomSeed &quot;:42}&quot;); char *molb = get_molblock(pkl,pkl_size,NULL); printf(&quot;%s n&quot;,molb); free(molb); free(pkl); } . We’ve already seen get_mol(). As mentioned above add_hs() modifies the molecule in place, so you need to pass pointers to the pickle string and pickle size so that they can be modifed. set_3d_coords() also modifies the molecule in place to add the conformer. This is also the first time we use the JSON string that most of the functions take as their last argument: here we set the random number seed used in the conformer generation so that we get reproducible results. Finally get_molblock(), like get_smiles(), returns a string with the MOL file data for the molecule. This can be saved to a file and opened in most chemistry software. . An aside about an interesting way rdkit-cffi could be used . The RDKit has a lot of functionality, and covering all of that in the interface exposed by rdkit-cffi is not a goal. We want to provide a useful (hopefully very useful) subset of the functionality for use in other languages. If there’s something you think is missing, please ask about it. . I think you there’s another interesting use case for this though. Suppose you have an idea for some interesting new piece of cheminformatics functionality, and you’d like to work in a language like Rust or Julia but you don’t want to have to deal with all the basic cheminformatics plumbing yourself. rdkit-cffi can really help here. The key functionality for this mode is the get_json() function, which returns an easily parsed JSON representation of the molecule using the RDKit’s extension to the commonchem JSON format. . void json_output(){ char *pkl; size_t pkl_size; pkl = get_mol(&quot;c1cc(O)ccc1&quot;,&amp;pkl_size,&quot;&quot;); char *json=get_json(pkl,pkl_size,NULL); printf(&quot;%s n&quot;,json); free(json); free(pkl); } . The output here (after running through a JSON pretty printer) is: . { &quot;commonchem&quot;: { &quot;version&quot;: 10 }, &quot;defaults&quot;: { &quot;atom&quot;: { &quot;z&quot;: 6, &quot;impHs&quot;: 0, &quot;chg&quot;: 0, &quot;nRad&quot;: 0, &quot;isotope&quot;: 0, &quot;stereo&quot;: &quot;unspecified&quot; }, &quot;bond&quot;: { &quot;bo&quot;: 1, &quot;stereo&quot;: &quot;unspecified&quot; } }, &quot;molecules&quot;: [ { &quot;atoms&quot;: [ { &quot;impHs&quot;: 1 }, { &quot;impHs&quot;: 1 }, {}, { &quot;z&quot;: 8, &quot;impHs&quot;: 1 }, { &quot;impHs&quot;: 1 }, { &quot;impHs&quot;: 1 }, { &quot;impHs&quot;: 1 } ], &quot;bonds&quot;: [ { &quot;bo&quot;: 2, &quot;atoms&quot;: [0,1] }, { &quot;atoms&quot;: [1,2] }, { &quot;atoms&quot;: [2,3] }, { &quot;bo&quot;: 2, &quot;atoms&quot;: [2,4] }, { &quot;atoms&quot;: [4,5] }, { &quot;bo&quot;: 2, &quot;atoms&quot;: [5,6] }, { &quot;atoms&quot;: [6,0] } ], &quot;extensions&quot;: [ { &quot;name&quot;: &quot;rdkitRepresentation&quot;, &quot;formatVersion&quot;: 1, &quot;toolkitVersion&quot;: &quot;2021.09.1pre&quot;, &quot;aromaticAtoms&quot;: [0,1,2,4,5,6], &quot;aromaticBonds&quot;: [0,1,3,4,5,6], &quot;atomRings&quot;: [[0,6,5,4,2,1] ] } ] } ] } . It should be easy to parse this with the JSON parser in any modern programming language, and the format provides all the information you need to reconstruct a molecule in whatever representation you’re using in your language of choice. But you can do it without having to worry about dealing with chemistry perception, ring finding, etc. . Status . The new CFFI interface is currently available on the RDKit master branch. It hasn’t yet been officially released, but I’m publicizing it now because I’d like to try and get people using it and providing feedback and suggestions so that we can get it as polished and useful as possible before the 2021.09 release later this year. . I’ve setup a separate repo in github which has a link to Azure Pipelines to automatically do builds of the CFFI wrappers and make the shared libraries available. The README there also includes links you can use to download the most recent builds for Linux and the Mac (I still need to get the automated Windows builds working). I haven’t figured out how to actually make this easy (unless you have the azure CLI installed, in which case there’s a single command you can execute), so there are a number of clicks needed: . Start by picking the build you want from the README: . Now click the build identifier (this page also has the azure CLI command to get the build directly): . Pick the appropriate job: . Click the “1 artifact” link: . now you can actually download the artifact: . sigh I will try to find a way to make this simpler… . Wrapping up . I will likely do another post on rdkit-cffi before the next release, most likely one looking at things like performance (since that’s something I tend to do). In the meantime please let me know if you start using it! .",
            "url": "https://greglandrum.github.io/rdkit-blog/technical/2021/05/01/rdkit-cffi-part1.html",
            "relUrl": "/technical/2021/05/01/rdkit-cffi-part1.html",
            "date": " • May 1, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "ETKDG and distance constraints",
            "content": "The RDKit&#39;s conformer generator allows you to provide distance &quot;constraints&quot; to bias the conformers which it produces. Last week I wondered how those constraints interact with the terms which the ETKDG algorithm adds to the &quot;distance geometry force field&quot;. . This post uses a simple example to explore that interaction . See another recent blog post for an overview of how the conformer generator works. . from rdkit import Chem from rdkit.Chem import rdDistGeom from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdMolTransforms IPythonConsole.ipython_3d = True from rdkit.Chem import Draw import rdkit print(rdkit.__version__) %pylab inline . 2020.09.4 Populating the interactive namespace from numpy and matplotlib . Here&#39;s the molecule we&#39;ll use: . m = Chem.AddHs(Chem.MolFromSmiles(&#39;OCCCCCCCN&#39;)) . from rdkit.Chem import rdDepictor m2d = Chem.Mol(m) rdDepictor.Compute2DCoords(m2d) IPythonConsole.drawOptions.addAtomIndices = True m2d . Get the bounds matrix for the molecule and look at the min/max values allowed for the O-N distance: . bounds = rdDistGeom.GetMoleculeBoundsMatrix(m) bounds[8,0],bounds[0,8] . (3.1500000000000004, 9.902933132591349) . Let&#39;s generate a bunch of conformers and look at the distribution of O-N distances: . figsize(6,6) ps = rdDistGeom.ETKDGv3() ps.randomSeed = 0xf00d cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists_etkdg = [rdMolTransforms.GetBondLength(conf,0,8) for conf in m.GetConformers()] hist(dists_etkdg,bins=20); title(&#39;ETKDG&#39;); xlabel(&#39;O--N distance&#39;); . Look at one conformer: . print(rdMolTransforms.GetBondLength(m.GetConformer(cids[0]),0,8) ) IPythonConsole.drawMol3D(m,confId=cids[1]) . 5.989729201561945 . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . Compare the distribution we get doing plain DG: . figsize(6,6) ps = rdDistGeom.EmbedParameters() ps.useExpTorsionAnglePrefs = False ps.useBasicKnowledge = False ps.randomSeed = 0xf00d cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,8) for conf in m.GetConformers()] hist(dists,bins=20); title(&#39;DG&#39;); xlabel(&#39;O--N distance&#39;); . There&#39;s not a giant difference, but it does look like the DG conformers for this molecule tend to be more extended: the O and N tend to be farther away from each other. . Here&#39;s how we can modify the bounds matrix to bring the O and N closer together: . bounds[0,8] = 4.1 bounds[8,0] = 4.0 from rdkit import DistanceGeometry DistanceGeometry.DoTriangleSmoothing(bounds) . True . Start with using this bounds matrix together with plain DG: . figsize(6,6) ps = rdDistGeom.EmbedParameters() ps.useExpTorsionAnglePrefs = False ps.useBasicKnowledge = False ps.randomSeed = 0xf00d ps.SetBoundsMat(bounds) cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,8) for conf in m.GetConformers()] hist(dists,bins=20); title(&#39;DG, distance constraints&#39;); xlabel(&#39;O--N distance&#39;); . print(rdMolTransforms.GetBondLength(m.GetConformer(cids[0]),0,8) ) IPythonConsole.drawMol3D(m,confId=cids[0]) . 3.9739942608788374 . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . When we do ETKDG we add additional terms to the force field that&#39;s used to optimize the structure. Do these override our distance constraints? . figsize(6,6) ps = rdDistGeom.ETKDGv3() ps.randomSeed = 0xf00d ps.SetBoundsMat(bounds) cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,8) for conf in m.GetConformers()] hist(dists,bins=20); title(&#39;ETKDG with constraints&#39;); xlabel(&#39;O--N distance&#39;); . Most of the distances are longer than what we were looking for, but they are still considerably shorter than what we saw before: . figsize(9,6) ps = rdDistGeom.ETKDGv3() ps.randomSeed = 0xf00d ps.SetBoundsMat(bounds) cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,8) for conf in m.GetConformers()] hist(dists,bins=20,label=&#39;constraints&#39;); title(&#39;ETKDG&#39;); hist(dists_etkdg,bins=20,label=&#39;no constraints&#39;); legend(); xlabel(&#39;O--N distance&#39;); . So that answers our original question: the &quot;constraints&quot; we place on the conformers by modifying the bounds matrix aren&#39;t strict, so the additional terms added by ETKDG can result in them being violated. But the results are still significant biased towards the region of conformer space we wanted to explore. . Let&#39;s try forcing conformations which have distances consistent with an intra-molecular hydrogen bond. Here we need to modify the bounds matrix elements between both the O and the N as well as the O and one of the Hs attached to the N. If we don&#39;t adjust the O-N distance bounds too we end up with a bounds matrix which cannot be smoothed. . bounds = rdDistGeom.GetMoleculeBoundsMatrix(m) bounds[0,25] = 1.9 bounds[25,0] = 1.8 bounds[0,8] = 3.2 bounds[8,0] = 2.9 from rdkit import DistanceGeometry DistanceGeometry.DoTriangleSmoothing(bounds) . True . figsize(9,6) ps = rdDistGeom.EmbedParameters() ps.useExpTorsionAnglePrefs = False ps.useBasicKnowledge = False ps.randomSeed = 0xf00d ps.SetBoundsMat(bounds) cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,25) for conf in m.GetConformers()] hist(dists,bins=20); xlabel(&#39;O--H-N distance&#39;); . print(rdMolTransforms.GetBondLength(m.GetConformer(cids[0]),0,25) ) IPythonConsole.drawMol3D(m,confId=cids[0]) . 1.9045497511922502 . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . Try using ETKDG: . figsize(6,6) ps = rdDistGeom.ETKDGv3() ps.randomSeed = 0xf00d ps.SetBoundsMat(bounds) cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,25) for conf in m.GetConformers()] hist(dists,bins=20); title(&#39;ETKDG, with constraints&#39;); xlabel(&#39;O--H-N distance&#39;); . print(rdMolTransforms.GetBondLength(m.GetConformer(cids[0]),0,25) ) IPythonConsole.drawMol3D(m,confId=cids[0]) . 2.0641816694294173 . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . The O--H-N distances here aren&#39;t completely obeying the 1.8-1.9 distance bounds we imposed, but they seem to match a bit better than what we saw above when we constrained the O--N distance. I think that&#39;s likely because now we have an additional constraining term - the O--H distance as well as the O--N distance - to help override the ETKDG preferences. . So to repeat the conclusion: modifying the distance bounds matrix doesn&#39;t act as a hard constraint when we include ETKDG terms in the conformer generation process, but it definitely biases the results towards the areas of conformer space which we were trying to access. .",
            "url": "https://greglandrum.github.io/rdkit-blog/conformers/exploration/2021/02/22/etkdg-and-distance-constraints.html",
            "relUrl": "/conformers/exploration/2021/02/22/etkdg-and-distance-constraints.html",
            "date": " • Feb 22, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Looking at random-coordinate embedding",
            "content": "This post discusses and shows the impact of the useRandomCoords option for the RDKit&#39;s conformer generator. . The RDKit&#39;s conformation generator is based on distance geometry. Here are the basic steps for the standard approach: . The molecule&#39;s distance bounds matrix is calculated based on the connection table and a set of rules. | The bounds matrix is smoothed using a triangle-bounds smoothing algorithm. | A random distance matrix that satisfies the bounds matrix is generated. | This distance matrix is embedded in 3 or 4 dimensions (producing coordinates for each atom). | The resulting coordinates are cleaned up somewhat using a crude force field (the &quot;distance geometry force field&quot;) and the bounds matrix. | If 4D embedding was done: another minimization is done with the distance geometry force field including a term to drive the 4th coordinate to zero. | If either experimental torsions (ET) or basic knowledge terms (K) are being used (the default is to use both because the conformations are higher quality), a final minimization is done using the &quot;ET&quot;, &quot;K&quot;, or &quot;ETK&quot; force fields. | Another way to generate the initial set of coordinates is to replace steps 3 and 4 with just picking a set of random coordinates (i.e. scatter the atoms randomly about a 3D box) and then moving on to step 5 and minimizing those using the distance geometry force field mentioned above. I learned of this approach from David Spellmeyer, who published it back in 1997: https://doi.org/10.1016/S1093-3263(97)00014-4 . Starting from random coordinates has been possible within the RDKit more or less since the beginning (I&#39;ve known David a long time ;-), but it&#39;s not the default because my implementation of it was slower than the standard embedding approach in the early testing and validation work I did. I&#39;ve been saying for years that random-coordinate embedding is more robust (though slower), but I haven&#39;t actually gone back and tested/quantified that since my initial experiments. This blog post aims to clear some of that up. . TL;DR: I ran some experiments using a set of 900 molecules with varying numbers of rotatable bonds and two different macrocycle sizes. Each molecule has at least two specified stereocenters. Given the current implementation, random-coordinate embedding is more robust - it&#39;s more likely to produce the requested number of conformers for these structures than the standard metric embedding is - but it still tends to be a bit slower. . Here&#39;s a graphical summary of the results: The main conclusion about timing can be see by comparing the red (metric) and blue (random) data. . Here&#39;s a plot comparing how long it takes to generate each conformer when trying for 50 conformers (left) or 50 more diverse conformers (right), the plot has been zoomed in, so a few extreme outliers (which impact the standard metric embedding more severely than the random-coordinate embedding) are not visible. . . Given that it is certainly more robust and that the overall performance difference isn&#39;t huge, I think I&#39;m likely to switch to using random-coordinate embedding for my future work. Maybe we can think about making it the default in the RDKit too. . For those who are interested, here&#39;s the original literature about ETKDG: . The original ETKDG publication: https://pubs.acs.org/doi/abs/10.1021/acs.jcim.5b00654 | Sereina Riniker&#39;s presentation at the 2015 RDKit UGM: https://github.com/rdkit/UGM_2015/blob/master/Presentations/ETKDG.SereinaRiniker.pdf | An update describing ETKDGv3 and extensions to better handle small rings and macrocycles: https://pubs.acs.org/doi/abs/10.1021/acs.jcim.0c00025 | . If you want to play with the compounds yourself, the SMILES are all in the rdkit_blog github repo . Ok, let&#39;s get to work and generate the data. . from rdkit import Chem from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdDepictor rdDepictor.SetPreferCoordGen(True) import pandas as pd import rdkit print(rdkit.__version__) %load_ext sql %pylab inline . 2020.09.4 The sql extension is already loaded. To reload it, use: %reload_ext sql Populating the interactive namespace from numpy and matplotlib . Collecting test molecules from ChEMBL . For this exercise I want a set of molecules which have varying numbers of rotatable bonds and which include at least two specified chiral centers. I include the constraint on chiral centers because the RDKit&#39;s conformation generator normally only returns conformations which match the specified stereochemistry. This can make conformation generation slower and I&#39;m curious to see the impact of that as part of this post. . Start with a few queries against my local copy of ChEMBL27 to see how many molecules with at least two specified chiral centers are available with different numbers of rotatable bonds: . %sql postgresql://localhost/chembl_27 select count(*) from compound_properties join compound_structures using (molregno) where rtb = 2 and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2; . 1 rows affected. . count . 14904 | . %sql postgresql://localhost/chembl_27 select count(*) from compound_properties join compound_structures using (molregno) where rtb = 5 and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2; . 1 rows affected. . count . 20586 | . %sql postgresql://localhost/chembl_27 select count(*) from compound_properties join compound_structures using (molregno) where rtb = 10 and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2; . 1 rows affected. . count . 9845 | . %sql postgresql://localhost/chembl_27 select count(*) from compound_properties join compound_structures using (molregno) where rtb = 15 and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2; . 1 rows affected. . count . 3834 | . %sql postgresql://localhost/chembl_27 select count(*) from compound_properties join compound_structures using (molregno) where rtb = 25 and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2; . 1 rows affected. . count . 1129 | . Looks like we can get plenty of molecules with up to 25 rotatable bonds, so let&#39;s go ahead and collect a set of 100 molecules for each of the rotatable bond counts 1, 2, 5, 10, 15, 20, and 25. I also include two additional sets of 100 molecules: one which contains at least one ring of size 10 and one which contains at least one ring of size 14. These macrocycles show up in what comes below with negative numbers of rotatable bonds: -10 for the compounds with a 10-ring and -14 for compounds with a 14-ring. . overall_data = [] for tgt in (1,2,5,10,15,20,25): d = %sql postgresql://localhost/chembl_27 select * from (select canonical_smiles,chembl_id,rtb from compound_properties join compound_structures using (molregno) join chembl_id_lookup on (molregno=entity_id and entity_type=&#39;COMPOUND&#39;) where rtb = :tgt and mw_freebase = full_mwt and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2) tmp order by random() limit 100; overall_data.extend(d) for tgt in (10,14): sma = f&#39;[r{tgt}]&#39; d = %sql postgresql://localhost/chembl_27 select * from (select canonical_smiles,chembl_id,-1 * :tgt from compound_properties join compound_structures using (molregno) join rdk.mols using (molregno) join chembl_id_lookup on (molregno=entity_id and entity_type=&#39;COMPOUND&#39;) where m@&gt;:sma ::qmol and mw_freebase = full_mwt and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2) tmp order by random() limit 100; overall_data.extend(d) with open(&#39;../data/chembl27_confgen_tgts.txt&#39;,&#39;w+&#39;) as outf: outf.write(&#39;SMILES CHEMBL_ID RTB n&#39;) for line in overall_data: outf.write(&#39; &#39;.join(str(x) for x in line)+&#39; n&#39;) . 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. . !head ../data/chembl27_confgen_tgts.txt . SMILES CHEMBL_ID RTB C[C@@H]1C[C@@]2(C)[C@@H](CC[C@H]3[C@@H]4CC[C@H](O)[C@@]4(C)CC[C@@H]32)C/C1=N N=C1/C[C@@H]2CC[C@H]3[C@@H]4CC[C@H](O)[C@@]4(C)CC[C@@H]3[C@@]2(C)C[C@H]1C CHEMBL2104408 1 CC(C)[C@@H]1OC(=O)C2(/C=C/c3ccc4ccc(nc4c3)[C@@H](C)NC(=O)[C@@H]3CCCN(N3)C(=O)[C@H](C)NC1=O)CCS(=O)(=O)CC2 CHEMBL4175329 1 CC(=O)O[C@H]1CCC[C@@H]2COC(=O)[C@@H]21 CHEMBL2228334 1 CNC(=O)O[C@H]1OC(=O)[C@H]2[C@H]3C=C[C@H](C3)[C@H]21 CHEMBL3989617 1 CC1(C)CC[C@]2(C)CC[C@]3(C(=O)O)C(=CC[C@@H]4[C@@]5(C)CC[C@H](O)C(C)(C)[C@@H]5CC[C@]43C)[C@@H]2C1 CHEMBL559587 1 CC1(C)[C@@H](O)CC[C@]2(C)C3=C(CC[C@@H]12)[C@@]1(C)CC[C@@]2(C)CC[C@@](C)(CO)C[C@H]2[C@]1(C)CC3 CHEMBL484238 1 C[C@]12CC[C@H](c3cc(F)c(O)cc3F)C[C@H]1CC[C@@H]2O CHEMBL1651144 1 Cc1cncc(C2=CC=C3[C@@H]4CCC5CNC(=O)CC[C@]5(C)[C@H]4CC[C@]23C)c1 CHEMBL3938064 1 C[C@H](O)[C@H]1O[C@@H]2SC(N3CCCC3)=N[C@@H]2[C@@H](O)[C@@H]1O CHEMBL3647379 1 . Run the experiments . Now we read those molecules back in and then start collecting data. . Here are the different experiments: . Generate a single conformer for each molecule. | Try to generate 50 conformers for each molecule. | Try to generate 50 diverse conformers for each molecule using an RMSD filter of 0.5 | Try to generate 50 conformers for each molecule ignoring stereochemistry | We will use ETKDGv3 and repeat each run once starting from standard embedding and once starting from random coordinates. . suppl = Chem.SmilesMolSupplier(&#39;../data/chembl27_confgen_tgts.txt&#39;) ms = [Chem.AddHs(m) for m in suppl] . from rdkit.Chem import AllChem from collections import defaultdict import time import pickle . Single conformer . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d metric_etkdg_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMolecule(m,ps) t2 = time.time() metric_etkdg_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.useRandomCoords = True random_etkdg_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMolecule(m,ps) t2 = time.time() random_etkdg_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,),outf) . 50 conformers . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 metric_etkdg50_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() metric_etkdg50_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.useRandomCoords = True random_etkdg50_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() random_etkdg50_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res,),outf) . Include RMS Pruning . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.pruneRmsThresh = 0.5 metric_etkdg50_rms_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() metric_etkdg50_rms_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.useRandomCoords = True ps.pruneRmsThresh = 0.5 random_etkdg50_rms_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() random_etkdg50_rms_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,random_etkdg50_rms_res),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.enforceChirality = False metric_etkdg50_nochiral_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() metric_etkdg50_nochiral_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,random_etkdg50_rms_res,metric_etkdg50_nochiral_res,),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.useRandomCoords = True ps.enforceChirality = False random_etkdg50_nochiral_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() random_etkdg50_nochiral_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,random_etkdg50_rms_res,metric_etkdg50_nochiral_res, random_etkdg50_nochiral_res),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.useRandomCoords = True ps.boxSizeMult = 1.0 random_etkdg50_box1_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() random_etkdg50_box1_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,random_etkdg50_rms_res,metric_etkdg50_nochiral_res, random_etkdg50_nochiral_res, random_etkdg50_box1_res),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.useRandomCoords = True ps.boxSizeMult = 0.5 random_etkdg50_box2_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() random_etkdg50_box2_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,random_etkdg50_rms_res,metric_etkdg50_nochiral_res, random_etkdg50_nochiral_res, random_etkdg50_box1_res, random_etkdg50_box2_res),outf) . Do the Analysis . figsize(15,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) subplot(1,2,1) for nrot in nrots: xp = [x[0] for x in metric_etkdg_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,3.5); ylim(0,4); plot((0,4),(0,4)) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); title(&#39;zoom&#39;); subplot(1,2,2) for nrot in nrots: xp = [x[0] for x in metric_etkdg_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); title(&#39;full range&#39;); . figsize(15,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) subplot(1,2,1) for nrot in nrots: xp = [x[0] for x in metric_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,50); ylim(0,80); plot((0,35),(0,35)) title(&#39;time (s)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); title(&#39;zoom&#39;); subplot(1,2,2) for nrot in nrots: xp = [x[0] for x in metric_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); #xlim(0,25); #ylim(0,35); plot((0,500),(0,500)) title(&#39;time (s)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); title(&#39;full range&#39;); . Number of conformers generated . figsize(7.5,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) print(f&#39;number of mols with below 50 conformers:&#39;) for nrot in nrots: xp = [x[1] for x in metric_etkdg50_res if x[-1]==nrot] yp = [x[1] for x in random_etkdg50_res if x[-1]==nrot] print(f&#39; {nrot} rotatable bonds, metric: {len([1 for x in xp if x!=50])} random: {len([1 for x in yp if x!=50])}&#39;) scatter(xp,yp,label=str(nrot)) legend(); #xlim(0,30); #ylim(0,40); #plot((0,30),(0,30)) title(&#39;num confs generated out of 50&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . number of mols with below 50 conformers: -14 rotatable bonds, metric: 8 random: 0 -10 rotatable bonds, metric: 1 random: 1 1 rotatable bonds, metric: 2 random: 2 2 rotatable bonds, metric: 2 random: 2 5 rotatable bonds, metric: 1 random: 1 10 rotatable bonds, metric: 4 random: 0 15 rotatable bonds, metric: 10 random: 0 20 rotatable bonds, metric: 27 random: 0 25 rotatable bonds, metric: 28 random: 0 . figsize(7.5,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) print(f&#39;number of mols with below 50 conformers:&#39;) for nrot in nrots: xp = [x[1] for x in metric_etkdg50_rms_res if x[-1]==nrot] yp = [x[1] for x in random_etkdg50_rms_res if x[-1]==nrot] print(f&#39; {nrot} rotatable bonds, metric: {len([1 for x in xp if x!=50])} random: {len([1 for x in yp if x!=50])}&#39;) scatter(xp,yp,label=str(nrot)) legend(); #xlim(0,30); #ylim(0,40); plot((0,50),(0,50)) title(&#39;num diverse confs generated out of 50&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . number of mols with below 50 conformers: -14 rotatable bonds, metric: 31 random: 17 -10 rotatable bonds, metric: 85 random: 83 1 rotatable bonds, metric: 99 random: 99 2 rotatable bonds, metric: 100 random: 100 5 rotatable bonds, metric: 93 random: 85 10 rotatable bonds, metric: 32 random: 19 15 rotatable bonds, metric: 13 random: 1 20 rotatable bonds, metric: 27 random: 0 25 rotatable bonds, metric: 28 random: 0 . figsize(7.5,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) print(f&#39;number of mols with below 50 conformers:&#39;) for nrot in nrots: xp = [x[1] for x in metric_etkdg50_nochiral_res if x[-1]==nrot] yp = [x[1] for x in random_etkdg50_nochiral_res if x[-1]==nrot] print(f&#39; {nrot} rotatable bonds, metric: {len([1 for x in xp if x!=50])} random: {len([1 for x in yp if x!=50])}&#39;) scatter(xp,yp,label=str(nrot)) legend(); #xlim(0,30); #ylim(0,40); #plot((0,30),(0,30)) title(&#39;num nochiral confs generated out of 50&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . number of mols with below 50 conformers: -14 rotatable bonds, metric: 6 random: 0 -10 rotatable bonds, metric: 0 random: 0 1 rotatable bonds, metric: 0 random: 0 2 rotatable bonds, metric: 0 random: 0 5 rotatable bonds, metric: 0 random: 0 10 rotatable bonds, metric: 2 random: 0 15 rotatable bonds, metric: 9 random: 0 20 rotatable bonds, metric: 26 random: 0 25 rotatable bonds, metric: 21 random: 0 . The random coordinate embedding produces 50 conformers in almost every case, while there are a significant number of examples where metric embedding is unable to produce all 50 conformers. . Time per conformer generated . figsize(15,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) subplot(1,2,1) for nrot in nrots: keep = [i for i,(x,y) in enumerate(zip(metric_etkdg50_res,random_etkdg50_res)) if x[-1]==nrot and x[1]!=0 and y[1]!=0] xp = [metric_etkdg50_res[x][0]/metric_etkdg50_res[x][1] for x in keep] yp = [random_etkdg50_res[x][0]/random_etkdg50_res[x][1] for x in keep] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,1.5); ylim(0,1.2); plot((0,.8),(0,.8)) title(&#39;time per conformer produced (4 threads)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); subplot(1,2,2) for nrot in nrots: keep = [i for i,(x,y) in enumerate(zip(metric_etkdg50_rms_res,random_etkdg50_rms_res)) if x[-1]==nrot and x[1]!=0 and y[1]!=0] xp = [metric_etkdg50_res[x][0]/metric_etkdg50_rms_res[x][1] for x in keep] yp = [random_etkdg50_res[x][0]/random_etkdg50_rms_res[x][1] for x in keep] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,1.5); ylim(0,2); plot((0,1),(0,1)) title(&#39;time per diverse conformer produced (4 threads)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . Look at the same thing without cropping outliers. . figsize(15,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) subplot(1,2,1) for nrot in nrots: keep = [i for i,(x,y) in enumerate(zip(metric_etkdg50_res,random_etkdg50_res)) if x[-1]==nrot and x[1]!=0 and y[1]!=0] xp = [metric_etkdg50_res[x][0]/metric_etkdg50_res[x][1] for x in keep] yp = [random_etkdg50_res[x][0]/random_etkdg50_res[x][1] for x in keep] scatter(xp,yp,label=str(nrot)) legend(); plot((0,3.5),(0,3.5)) title(&#39;time per conformer produced (4 threads)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); subplot(1,2,2) for nrot in nrots: keep = [i for i,(x,y) in enumerate(zip(metric_etkdg50_rms_res,random_etkdg50_rms_res)) if x[-1]==nrot and x[1]!=0 and y[1]!=0] xp = [metric_etkdg50_res[x][0]/metric_etkdg50_rms_res[x][1] for x in keep] yp = [random_etkdg50_res[x][0]/random_etkdg50_rms_res[x][1] for x in keep] scatter(xp,yp,label=str(nrot)) legend(); plot((0,3.5),(0,3.5)) title(&#39;time per diverse conformer produced (4 threads)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . Note that these times per conformer cannot be directly compared to the time to generate a single conformer since these were run using multiple threads. . Ignoring chirality . figsize(7.5,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) for nrot in nrots: xp = [x[0] for x in metric_etkdg50_nochiral_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_nochiral_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); #xlim(0,30); #ylim(0,40); plot((0,15),(0,15)) title(&#39;nochiral time(s)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . General impact of ignoring chirality . nrots = sorted(set(x[-1] for x in metric_etkdg_res)) figsize(15,6) subplot(1,2,1) for nrot in nrots: xp = [x[0] for x in metric_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in metric_etkdg50_nochiral_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,50); ylim(0,30); plot((0,30),(0,30)) title(&#39;metric embedding time(s)&#39;) xlabel(&#39;chiral&#39;) ylabel(&#39;nochiral&#39;); subplot(1,2,2) for nrot in nrots: xp = [x[0] for x in random_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_nochiral_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,50); ylim(0,40); plot((0,40),(0,40)) title(&#39;random embedding time(s)&#39;) xlabel(&#39;chiral&#39;) ylabel(&#39;nochiral&#39;); . Impact of box size on random embedding . nrots = sorted(set(x[-1] for x in metric_etkdg_res)) figsize(15,6) subplot(1,2,1) for nrot in nrots: xp = [x[0] for x in random_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_box1_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,80); ylim(0,80); plot((0,60),(0,60)) title(&#39;random embedding time(s)&#39;) xlabel(&#39;mult=2 (default)&#39;) ylabel(&#39;mult=1&#39;); subplot(1,2,2) for nrot in nrots: xp = [x[0] for x in random_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_box2_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,80); ylim(0,80); plot((0,60),(0,60)) title(&#39;random embedding time(s)&#39;) xlabel(&#39;mult=2 (default)&#39;) ylabel(&#39;mult=0.5&#39;); . Summaries . def set_box_color(bp, color): setp(bp[&#39;boxes&#39;], color=color) setp(bp[&#39;whiskers&#39;], color=color) setp(bp[&#39;caps&#39;], color=color) setp(bp[&#39;medians&#39;], color=color) setp(bp[&#39;fliers&#39;], markeredgecolor=color) figsize(15,6) ax = axes() ax.set_yscale(&#39;log&#39;); ax.set_ylabel(&#39;time(s)&#39;) ax.set_xlabel(&#39;nrot&#39;) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) d = [[x[0] for x in metric_etkdg50_res if x[-1]==nrot] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x for x in range(len(d))]); set_box_color(bp,&#39;r&#39;) d = [[x[0] for x in random_etkdg50_res if x[-1]==nrot] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+.5 for x in range(len(d))]); set_box_color(bp,&#39;b&#39;) d = [[x[0] for x in random_etkdg50_nochiral_res if x[-1]==nrot] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+1 for x in range(len(d))]); set_box_color(bp,&#39;c&#39;) d = [[x[0] for x in random_etkdg50_box1_res if x[-1]==nrot] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+1.5 for x in range(len(d))]); set_box_color(bp,&#39;m&#39;) d = [[x[0] for x in random_etkdg50_box2_res if x[-1]==nrot] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+2 for x in range(len(d))]); set_box_color(bp,&#39;y&#39;) #set_axis_style(ax, [str(x) for x in nrots]) ticks = [str(x) for x in nrots] xticks(np.arange(0, len(ticks) * 3, 3)+1, ticks); plot([], c=&#39;r&#39;, label=&#39;metric&#39;) plot([], c=&#39;b&#39;, label=&#39;random&#39;) plot([], c=&#39;c&#39;, label=&#39;random-nochiral&#39;) plot([], c=&#39;m&#39;, label=&#39;random-box1&#39;) plot([], c=&#39;y&#39;, label=&#39;random-box0.5&#39;) legend(); . def set_box_color(bp, color): setp(bp[&#39;boxes&#39;], color=color) setp(bp[&#39;whiskers&#39;], color=color) setp(bp[&#39;caps&#39;], color=color) setp(bp[&#39;medians&#39;], color=color) setp(bp[&#39;fliers&#39;], markeredgecolor=color) figsize(15,6) ax = axes() ax.set_yscale(&#39;log&#39;); ax.set_ylabel(&#39;time per conformer (s)&#39;) ax.set_xlabel(&#39;nrot&#39;) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) d = [[x[0]/x[2].GetNumConformers() for x in metric_etkdg50_res if x[-1]==nrot and x[2].GetNumConformers()!=0] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x for x in range(len(d))]); set_box_color(bp,&#39;r&#39;) d = [[x[0]/x[2].GetNumConformers() for x in metric_etkdg50_rms_res if x[-1]==nrot and x[2].GetNumConformers()!=0] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+.5 for x in range(len(d))]); set_box_color(bp,&#39;c&#39;) d = [[x[0]/x[2].GetNumConformers() for x in random_etkdg50_res if x[-1]==nrot and x[2].GetNumConformers()!=0] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+1 for x in range(len(d))]); set_box_color(bp,&#39;b&#39;) d = [[x[0]/x[2].GetNumConformers() for x in random_etkdg50_rms_res if x[-1]==nrot and x[2].GetNumConformers()!=0] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+1.5 for x in range(len(d))]); set_box_color(bp,&#39;m&#39;) #set_axis_style(ax, [str(x) for x in nrots]) ticks = [str(x) for x in nrots] xticks(np.arange(0, len(ticks) * 3, 3)+1, ticks); plot([], c=&#39;r&#39;, label=&#39;metric&#39;) plot([], c=&#39;c&#39;, label=&#39;metric-diverse&#39;) plot([], c=&#39;b&#39;, label=&#39;random&#39;) plot([], c=&#39;m&#39;, label=&#39;random-diverse&#39;) legend(); . Look at some of the troublesome structures . Which ones couldn&#39;t we generate conformers for? . no_confs_metric_etkdg50 = set([i for i,x in enumerate(metric_etkdg50_res) if x[2].GetNumConformers()==0]) no_confs_random_etkdg50 = set([i for i,x in enumerate(metric_etkdg50_res) if x[2].GetNumConformers()==0]) print(f&#39;metric: {len(no_confs_metric_etkdg50)}, random embedding: {len(no_confs_random_etkdg50)}, overlap: {len(no_confs_metric_etkdg50.union(no_confs_random_etkdg50))}&#39;) . metric: 13, random embedding: 13, overlap: 13 . dms = [Chem.RemoveHs(ms[i]) for i in no_confs_metric_etkdg50] dms = [m for m in dms if m.GetNumAtoms()&lt;75] Draw.MolsToGridImage(dms,subImgSize=(300,250),molsPerRow=3, legends=[m.GetProp(&#39;_Name&#39;) for m in dms]) . dms = [Chem.RemoveHs(ms[i]) for i in no_confs_metric_etkdg50] dms = [m for m in dms if m.GetNumAtoms()&gt;=75] from IPython.display import SVG d2d = Draw.MolDraw2DSVG(800,350) d2d.DrawMolecule(dms[0]) d2d.FinishDrawing() SVG(d2d.GetDrawingText()) . Ok, some of those are quite constrained and have a fair number of chiral centers, so it&#39;s easy to imagine them being hard to embed. Some (like CHEMBL59404) are just peptides though... seems like those should be manageable. Something to look into . What about the structures which embed but take a really long time? . slow_metric_etkdg50 = [y for x,y in sorted([(x[0],i) for i,x in enumerate(metric_etkdg50_res) if x[2].GetNumConformers()],reverse=True)][:5] dms = [Chem.RemoveHs(ms[i]) for i in slow_metric_etkdg50] #dms = [m for m in dms if m.GetNumAtoms()&lt;75] Draw.MolsToGridImage(dms,subImgSize=(300,250),molsPerRow=3, legends=[m.GetProp(&#39;_Name&#39;) for m in dms]) . IPythonConsole.ipython_3d = True metric_etkdg50_res[slow_metric_etkdg50[0]][2] . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . metric_etkdg50_res[slow_metric_etkdg50[4]][2] . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol .",
            "url": "https://greglandrum.github.io/rdkit-blog/conformers/exploration/2021/01/31/looking-at-random-coordinate-embedding.html",
            "relUrl": "/conformers/exploration/2021/01/31/looking-at-random-coordinate-embedding.html",
            "date": " • Jan 31, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Sphere exclusion clustering with the RDKit",
            "content": "Roger Sayle contributed an implementation of sphere-exclusion picking to the RDKit as part of the 2019.09 release and I recently realized that I&#39;d never blogged about that code or how to use it to do compound clustering. So here&#39;s a short(ish) one. . The RDKit has had an implementation of the MaxMin algorithm for picking diverse compounds for quite a while (Roger made this a lot faster back in 2017). The input to the MaxMin picker is the number of diverse compounds you want. The new algorithm is different: you provide the minimum distance allowed between the compounds picked and it returns a set of compounds satisfying that constraint. . Both of these methods for picking diverse compounds can then be converted into clustering algorithms by defining those picked points to be cluster centroids and then assigning non-picked compounds to the nearest centroid. We&#39;ll do that here for the sphere-exclusion algorithm. . Further reading: . for more about the sphere-exclusion picker and/or learn how it works: here&#39;s Roger&#39;s UGM presentation | Roger&#39;s UGM presentation describing his fast implementation of the MaxMin picker is here | Tim Dudgeon&#39;s guest post on this blog provides a nice overview of the new MaxMin picker. | . from rdkit import Chem from rdkit import DataStructs from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdDepictor, rdMolDescriptors import time rdDepictor.SetPreferCoordGen(True) import rdkit %pylab inline print(rdkit.__version__) . Populating the interactive namespace from numpy and matplotlib 2020.09.1 . First dataset . The dataset we&#39;ll start with is the &quot;new Lessel and Briem&quot; set that I put together as part of this blog post . ms = [x for x in Chem.SmilesMolSupplier(&#39;../data/BLSets_selected_actives.txt&#39;)] len(ms) . 6359 . We&#39;ll use MFP2 fingerprints: . from rdkit.Chem import rdMolDescriptors fps = [rdMolDescriptors.GetMorganFingerprintAsBitVect(m,2,2048) for m in ms] . The new sphere-exclusion code is available using the LeaderPicker: . from rdkit.SimDivFilters import rdSimDivPickers lp = rdSimDivPickers.LeaderPicker() . And we pick compounds by giving the picker the fingerprints and a minimum distance between cluster centroids. Here we&#39;re using a distance threshold of 0.65, which is the random-similarity threshold I found for MFP2 fingeprints. . thresh = 0.65 # &lt;- minimum distance between cluster centroids picks = lp.LazyBitVectorPick(fps,len(fps),thresh) print(len(picks)) . 535 . For reference, here&#39;s how long that takes to run: . %timeit lp.LazyBitVectorPick(fps,len(fps),thresh) . 41.9 ms ± 262 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) . Let&#39;s look at some of those picked compounds: . Draw.MolsToGridImage([ms[x] for x in picks[:12]],molsPerRow=4) . Just to get a feeling for what&#39;s going on, calculate the similarities between the compounds that have been picked. . from rdkit import DataStructs pickfps = [fps[x] for x in picks] nearest = [] simhist = [] for i,fpi in enumerate(pickfps): tfps = pickfps[:] del tfps[i] sims = DataStructs.BulkTanimotoSimilarity(fpi,tfps) nearest.append(max(sims)) simhist.extend(sims) sorted(nearest,reverse=True)[:10] . [0.3492063492063492, 0.3492063492063492, 0.3492063492063492, 0.3492063492063492, 0.3488372093023256, 0.3488372093023256, 0.3488372093023256, 0.3488372093023256, 0.3488372093023256, 0.3488372093023256] . Remember that we defined a distance threshold of 0.65, so there should be no similarity values above 0.35 here. It&#39;s good to see that this is true. . Here&#39;s the histogram of distances . hist(simhist,bins=20); xlabel(&#39;similarity&#39;); . Now let&#39;s assign points to clusters. As mentioned above, we do that by defining the picked compounds to be the centroids and then assign each other compound in the dataset to the nearest cluster centroid. . We don&#39;t currently have a single call for doing this, so here&#39;s a Python function: . from collections import defaultdict import numpy as np def assignPointsToClusters(picks,fps): clusters = defaultdict(list) for i,idx in enumerate(picks): clusters[i].append(idx) sims = np.zeros((len(picks),len(fps))) for i in range(len(picks)): pick = picks[i] sims[i,:] = DataStructs.BulkTanimotoSimilarity(fps[pick],fps) sims[i,i] = 0 best = np.argmax(sims,axis=0) for i,idx in enumerate(best): if i not in picks: clusters[idx].append(i) return clusters . clusters = assignPointsToClusters(picks,fps) hist([len(clusters[x]) for x in clusters]); xlabel(&#39;cluster size&#39;); . hist([len(clusters[x]) for x in clusters],log=True); xlabel(&#39;cluster size&#39;); . Unfortunately this implementation for assigning compounds to clusters isn&#39;t particularly efficient since it makes a bunch of calls across the Python/C++ interface: . %timeit assignPointsToClusters(picks,fps) . 360 ms ± 10.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) . I hope to have the chance to improve the performance of this step in a future RDKit release. . Looking at the clusters . Let&#39;s look at the compounds inside a couple of clusters in order to see how closely related they seem to be: . clusts12 = [x for x in clusters if len(clusters[x])==12] len(clusts12) . 10 . Draw.MolsToGridImage([ms[x] for x in clusters[clusts12[0]]],molsPerRow=4) . We can also look at the intra-cluster similarities . def intracluster_similarities(cluster,fps): res = [] cfps = [fps[x] for x in cluster] for i,fpid in enumerate(cluster): tres = DataStructs.BulkTanimotoSimilarity(cfps[i],cfps) del tres[i] res.extend(tres) return res . hist(intracluster_similarities(clusters[clusts12[0]],fps)); xlabel(&#39;Similarity&#39;); . Draw.MolsToGridImage([ms[x] for x in clusters[clusts12[1]]],molsPerRow=4) . hist(intracluster_similarities(clusters[clusts12[1]],fps)); xlabel(&#39;Similarity&#39;); . Both clusters are clearly include related compounds . Decreasing the sphere radius . What about if we make the clusters tighter by decreasing the threshold distance? . thresh = 0.35 # &lt;- minimum distance between cluster centroids picks = lp.LazyBitVectorPick(fps,len(fps),thresh) print(len(picks)) . 1832 . clusters = assignPointsToClusters(picks,fps) hist([len(clusters[x]) for x in clusters]); xlabel(&#39;cluster size&#39;); . We&#39;ve got more clusters and they are smaller. No big surprise . And let&#39;s look at a couple of those . clusts12 = [x for x in clusters if len(clusters[x])==12] len(clusts12) . 17 . Draw.MolsToGridImage([ms[x] for x in clusters[clusts12[0]]],molsPerRow=4) . hist(intracluster_similarities(clusters[clusts12[0]],fps)); xlabel(&#39;Similarity&#39;); . Draw.MolsToGridImage([ms[x] for x in clusters[clusts12[1]]],molsPerRow=4) . hist(intracluster_similarities(clusters[clusts12[1]],fps)); xlabel(&#39;Similarity&#39;); . Again, those mostly look quite similar to each other, maybe even more similar than before? . Impact of sphere radius on the number of clusters . Look at the number of clusters as a function of the threshold . results = [] for thresh in arange(0.65,0.05,-0.05): tpicks = lp.LazyBitVectorPick(fps,len(fps),thresh) results.append([thresh,len(tpicks)]) . scatter([x for x,y in results],[y for x,y in results]); ylabel(&#39;number of clusters&#39;) xlabel(&#39;distance threshold&#39;) . Text(0.5, 0, &#39;distance threshold&#39;) . Trying a larger dataset . I said that Roger&#39;s implementation was efficient, but the dataset above wasn&#39;t all that big. Let&#39;s try a larger one. . Here we&#39;ll use the full set of compounds I grabbed data for when building the new &quot;Lessel and Briem&quot; datasets. . As an aside, this is also a nice opportunity to demonstrate using the MultithreadedSmilesMolSupplier that Shrey Aryan added to the RDKit as part of his 2020 Google Summer of Code project. This new supplier allows molecules to be constructed in parallel and can, in some situations, really speed things up. . t1 = time.time() fps = [rdMolDescriptors.GetMorganFingerprintAsBitVect(m,2,2048) for m in Chem.MultithreadedSmilesMolSupplier(&#39;../data/BLSets_actives.txt&#39;,numWriterThreads=4,delimiter=&#39; t&#39;) if m is not None] t2 = time.time() print(f&quot;That took {t2-t1 :.2f} seconds to build {len(fps)} fingerprints&quot;) . That took 6.02 seconds to build 91663 fingerprints . Running that single threaded (i.e. using a normal SmilesMolSupplier) took 16.8 seconds on my machine. . Pick the cluster centroids: . lp = rdSimDivPickers.LeaderPicker() thresh = 0.65 # &lt;- minimum distance between cluster centroids picks = lp.LazyBitVectorPick(fps,len(fps),thresh) print(len(picks)) . 2997 . How long does that take? . %timeit lp.LazyBitVectorPick(fps,len(fps),thresh) . 5.14 s ± 320 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) . t1 = time.time() clusters = assignPointsToClusters(picks,fps) t2=time.time() print(f&quot;That took {t2-t1 :.2f} seconds&quot;) hist([len(clusters[x]) for x in clusters]); xlabel(&#39;cluster size&#39;); . That took 43.34 seconds . And, finally, look at the number of clusters and clustering time as a function of the sphere radius . results = [] for thresh in (0.2,0.3,0.4,0.5,0.6,0.7,0.8): lp = rdSimDivPickers.LeaderPicker() t1 = time.time() picks = lp.LazyBitVectorPick(fps,len(fps),thresh) t2 = time.time() print(f&quot;distance threshold {thresh: .2f}, {len(picks)} clusters in {t2-t1 :.2f} seconds&quot;) results.append((thresh,len(picks),t2-t1)) . distance threshold 0.20, 34535 clusters in 66.25 seconds distance threshold 0.30, 20627 clusters in 37.51 seconds distance threshold 0.40, 11799 clusters in 21.47 seconds distance threshold 0.50, 6811 clusters in 12.48 seconds distance threshold 0.60, 4047 clusters in 7.02 seconds distance threshold 0.70, 2021 clusters in 3.07 seconds distance threshold 0.80, 558 clusters in 0.51 seconds . Those two track nicely with each other; more clusters = longer run time: . fig, ax = subplots() ax.plot([x[0] for x in results],[x[1] for x in results]); ax.set_xlabel(&#39;Sphere radius&#39;); ax.set_ylabel(&#39;Num clusters&#39;); ax2 = ax.twinx() ax2.plot([x[0] for x in results],[x[2] for x in results],c=&#39;r&#39;); ax2.set_ylabel(&#39;Time (s)&#39;); .",
            "url": "https://greglandrum.github.io/rdkit-blog/similarity/tutorial/2020/11/18/sphere-exclusion-clustering.html",
            "relUrl": "/similarity/tutorial/2020/11/18/sphere-exclusion-clustering.html",
            "date": " • Nov 18, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Setting up an environment to make Python contributions to the RDKit",
            "content": "It has been tricky to contribute code or documentation to the RDKit if you’re a Python programmer who doesn’t want to deal with the complexities of getting an RDKit build working. We want to make it straightforward for people to contribute, so I’m working on some recipes to make thigs easier. This is the first pass at that. . In order to fix bugs or add features in Python you need to be able to clone a local fork of the RDKit from github, modify the code in that local clone, and then run the local code in order to test it. The problem is that most RDKit functionality requires some binary components that need to be built from C++ and installed in the appropriate places. We’re going to work around that problem here by copying the binary components from a recent binary distribution of the RDKit into a local clone of the RDKit repo. . I’m going to explain each of the required steps, but the complete set of steps required is at the bottom of this post. Assuming that you have the prerequisites (explained directly below), I hope that these will “just work” for you, but one never knows… I’d like to be able to include this in the RDKit documentation, so please me know how it goes if you try the recipe out. Please do not add a comment to this blog post, I’ve created a github issue so that we have the comments in one place. If you don’t have a github account, please email me your comments and I’ll add them to the issue. . The steps explained . At the moment this recipe only works on linux and the mac. I will put together a similar recipe for windows and either do a separate post or update this one. . Prerequisites: . you need to have either anaconda python or miniconda installed and in your path | you need to have git installed and in your path | . You should start by changing into the directory where you want to clone the RDKit source repository and then running: . git clone https://github.com/rdkit/rdkit.git . That will clone the repo from github into a local directory called rdkit. We now change into that directory and use it to set our RDBASE environment variable: . cd rdkit export RDBASE=`pwd` . The next step is to create the conda environment that we’re going to use to hold the RDKit binary components and install a recent beta version of the RDKit into that environment: . conda create -y -n py37_rdkit_beta python=3.7 conda activate py37_rdkit_beta conda install -y -c rdkit/label/beta rdkit . If you have other Python packages that you’d like to work with, go ahead and install them into the environment now. . Next we copy the RDKit binary components from that environment into our local clone of the RDKit repo: . cd $CONDA_PREFIX/lib/python3.7/site-packages/rdkit rsync -a -m --include &#39;*/&#39; --include=&#39;*.so&#39; --include=&#39;inchi.py&#39; --exclude=&#39;*&#39; . $RDBASE/rdkit . NOTE: that rsync command should be one long line. . Finally we set our PYTHONPATH and then test that everything is working by importing the RDKit’s Chem module: . export PYTHONPATH=&quot;$RDBASE&quot; cd $RDBASE/rdkit python -c &#39;from rdkit import Chem;print(Chem.__file__)&#39; . That last command should not generate errors and should show you a filename that is in your local github clone. As an example, I started the first step of this process in my /scratch/rdkit_devel directory, so I see: . /scratch/rdkit_devel/rdkit/rdkit/Chem/__init__.py . Running the tests . If you’re planning on making an RDKit contribution, it’s important to know how to run the Python tests to make sure that your changes work and don’t break anything else. For historic reasons the RDKit uses a self-written framework for running tests, but it’s easy enough to use. You need to run the script $RDBASE/rdkit/TestRunner.py and point it to the test_list.py file containing the tests to be run. For example, if you want to run all the tests in the directory $RDBASE/rdkit/Chem (this corresponds to the python module rdkit.Chem), you would do: . cd $RDBASE/rdkit/Chem python $RDBASE/rdkit/TestRunner.py test_list.py . That will take a while and generate a lot of output, including things that look like exceptions and errors, but should finish with something like: . Script: test_list.py. Passed 40 tests in 69.70 seconds . Finishing up . You’re set. The one thing to remember is that whenever you want to use this environment in a new terminal window or shell, you need to activate the py37_rdkit_beta conda environment (don’t delete it!), set RDBASE, and set your PYTHONPATH: . conda activate py37_rdkit_beta cd your_local_rdkit_clone # &lt;- replace this with the real name of the directory export RDBASE=`pwd` export PYTHONPATH=&quot;$RDBASE&quot; . The recipe . Here’s the complete recipe: . git clone https://github.com/rdkit/rdkit.git cd rdkit export RDBASE=`pwd` conda create -y -n py37_rdkit_beta python=3.7 conda activate py37_rdkit_beta conda install -y -c rdkit/label/beta rdkit cd $CONDA_PREFIX/lib/python3.7/site-packages/rdkit rsync -a -m --include &#39;*/&#39; --include=&#39;*.so&#39; --include=&#39;inchi.py&#39; --exclude=&#39;*&#39; . $RDBASE/rdkit export PYTHONPATH=&quot;$RDBASE&quot; cd $RDBASE/rdkit python -c &#39;from rdkit import Chem;print(Chem.__file__)&#39; .",
            "url": "https://greglandrum.github.io/rdkit-blog/contributing/tutorial/2020/03/30/setting-up-an-environment.html",
            "relUrl": "/contributing/tutorial/2020/03/30/setting-up-an-environment.html",
            "date": " • Mar 30, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Finding regioisomers",
            "content": "This is one that came up recently on the mailing list that I thought made for a good example to demonstrate how to write Python to do some more advanced structural searches with the RDKit. . from rdkit import Chem from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole import rdkit print(rdkit.__version__) . 2019.09.3 . RDKit WARNING: [05:43:19] Enabling RDKit 2019.09.3 jupyter extensions . My paraphrasing of the problem: Alexis wanted to be able to do the equivalent of a substructure search that finds all aromatic rings that have both Cl and Br substituents. So he wanted to be able to match the first two of these, but not the second: . ms = [Chem.MolFromSmiles(x) for x in &#39;Clc1c(Br)cccc1 Clc1cc(Br)ccc1 Clc1cccc2c1c(Br)ccc2&#39;.split()] Draw.MolsToGridImage(ms,legends=&#39;match match no-match&#39;.split()) . It&#39;s really non-trivial to do this with SMARTS since it has no way to express that two atoms should be in the same ring without making the ring explicit in the SMARTS. I was able to come up with this SMARTS, which works, but is unwieldy (at best): . p = Chem.MolFromSmarts(&#39;Cl[c;$(c1(Cl)c(Br)cccc1),$(c1(Cl)cc(Br)ccc1),$(c1(Cl)ccc(Br)cc1)]&#39;) print([m.HasSubstructMatch(p) for m in ms]) . [True, True, False] . So that does what we want, but it only handles six rings where every atom is a C. That second part is easy enough to change in the SMARTS, but handling other ring sizes starts to make the SMARTS really long. . A more difficult problem is that, because we use recursive SMARTS, we can&#39;t get the atoms matching the query. The pattern I used above would only return the Cl atom and the C atom it&#39;s connected to. I&#39;m not sure Alexis even wanted to do that, but by this point I was interested in the problem and decided to write some Python to solve the problem flexibly. . Here we go. . Before introducing the code and showing what it can do, a quick intro on the two pieces of functionality I&#39;m going to be using from Python&#39;s itertools module. These are really useful. . Let&#39;s start with using itertools to flatten a sequence of sequences: . import itertools seqs = [[1,2,3],[&#39;a&#39;,&#39;b&#39;],[10,20]] list(itertools.chain.from_iterable(seqs)) . [1, 2, 3, &#39;a&#39;, &#39;b&#39;, 10, 20] . And to generate all the permutations of combinations of those sequences: . list(itertools.product(*seqs)) . [(1, &#39;a&#39;, 10), (1, &#39;a&#39;, 20), (1, &#39;b&#39;, 10), (1, &#39;b&#39;, 20), (2, &#39;a&#39;, 10), (2, &#39;a&#39;, 20), (2, &#39;b&#39;, 10), (2, &#39;b&#39;, 20), (3, &#39;a&#39;, 10), (3, &#39;a&#39;, 20), (3, &#39;b&#39;, 10), (3, &#39;b&#39;, 20)] . Ok, that&#39;s the background, let&#39;s define the functions we&#39;ll use: . import itertools def getAromaticRings(mol): &quot;&quot;&quot; generator returning all aromatic rings (=only aromatic bonds) in a molecule Parameters - mol : Mol Yields set IDs of the atoms in an aromatic ring &quot;&quot;&quot; ri = mol.GetRingInfo() for ring in ri.BondRings(): ats = set() isArom = True for bi in ring: bnd = mol.GetBondWithIdx(bi) if not bnd.GetIsAromatic(): isArom = False break ats.add(bnd.GetBeginAtomIdx()) ats.add(bnd.GetEndAtomIdx()) if isArom: yield ats def getSharedRings(mol,queries,rings=None,excludeQueries=None): &quot;&quot;&quot; generator returning all rings that contain all the atoms defined in queries the first atom matching each query should be in the ring Parameters - mol : Mol queries : sequence of Mols rings : list/tuple/set of list/tuple/sets, optional sequence of rings defined by sequences of atom ids If this isn&#39;t provided, all of the molecule&#39;s rings will be used excludeQueries : sequence of Mols, optional any ring containing an atom matching the first atom in any of these queries will be excluded Yields - set containing atom IDs for a matching ring &quot;&quot;&quot; if rings is None: rings = mol.GetRingInfo().AtomRings() alreadySeen = [] rings = [set(x) for x in rings] matchSets = [[x[0] for x in mol.GetSubstructMatches(q)] for q in queries] if excludeQueries is not None: exclude = [[x[0] for x in mol.GetSubstructMatches(q)] for q in excludeQueries] # flatten the lists of matches into a set: exclude = set(itertools.chain.from_iterable(exclude)) else: exclude = set() for combo in itertools.product(*matchSets): scombo = set(combo) if len(scombo) &lt; len(combo): # degenerate: continue for ring in rings: if ring in alreadySeen: continue if scombo.issubset(ring) and exclude.isdisjoint(ring): alreadySeen.append(ring) yield ring def drawMolWithRings(mol,rings): &quot;&quot;&quot; draws a molecule with a set of rings highlighted Parameters - mol : Mol rings : list/tuple/set of list/tuple/sets sequence of rings defined by sequences of atom IDs Returns - Image &quot;&quot;&quot; bondsToHighlight=[] for bnd in mol.GetBonds(): keep = False ats = set([bnd.GetBeginAtomIdx(),bnd.GetEndAtomIdx()]) for ring in rings: if ats.issubset(ring): keep = True break if keep: bondsToHighlight.append(bnd.GetIdx()) highlightAtoms = list(itertools.chain.from_iterable(rings)) tmol = Draw.PrepareMolForDrawing(mol) d2d = Draw.MolDraw2DCairo(300, 250) d2d.DrawMolecule(tmol, highlightAtoms=highlightAtoms, highlightBonds = bondsToHighlight) d2d.FinishDrawing() return Draw._drawerToImage(d2d) . This is the molecule we&#39;ll work with: . mol = Chem.MolFromSmiles(&#39;c1c(Cl)cc(Br)c2c1CCc3c2cc(Cl)c4c3CCC(Cl)C4Br&#39;) mol . Show what the getAromaticRings() function returns here: . rings = list(getAromaticRings(mol)) rings . [{0, 1, 3, 4, 6, 7}, {10, 11, 12, 13, 15, 16}] . We can use drawMolWithRings() to highlight those atoms: . drawMolWithRings(mol,rings) . Now let&#39;s look at Alexis&#39; question: find all the aromatic rings that have a Cl and a Br attached: . matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[a]-Cl&#39;,&#39;[a]-Br&#39;)], rings=getAromaticRings(mol))) print(matches) drawMolWithRings(mol,matches) . [{0, 1, 3, 4, 6, 7}] . What about aromatic rings that have both a Cl and an aliphatic C attached? . matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[a]-Cl&#39;,&#39;[a]-C&#39;)], rings=getAromaticRings(mol))) print(matches) drawMolWithRings(mol,matches) . [{0, 1, 3, 4, 6, 7}, {16, 10, 11, 12, 13, 15}] . What about just finding any rings (not just aromatic) that have both Cl and Br connected? . Here we just drop the rings argument to getSharedRings(), it will use all of the molecule&#39;s rings: . matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[*]-Cl&#39;,&#39;[*]-Br&#39;)])) print(matches) drawMolWithRings(mol,matches) . [{0, 1, 3, 4, 6, 7}, {15, 16, 17, 18, 19, 21}] . We can also find any rings that have a Cl, but not a Br: . matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[*]-Cl&#39;,)], excludeQueries=[Chem.MolFromSmarts(sma) for sma in (&#39;[*]-Br&#39;,)])) print(matches) drawMolWithRings(mol,matches) . [{10, 11, 12, 13, 15, 16}] . We aren&#39;t limited to just six membered rings, of course. Go back to the original query for aromatic rings with both Cl and Br attached: . mol = Chem.MolFromSmiles(&#39;Clc1[nH]c(Br)c(c2ccc(Cl)c(Br)c2)c1&#39;) matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[*]-Cl&#39;,&#39;[*]-Br&#39;)], rings=getAromaticRings(mol))) print(matches) drawMolWithRings(mol,matches) . [{1, 2, 3, 5, 14}, {6, 7, 8, 9, 11, 13}] . What about aromatic rings that have both Cl and Br attached, but that don&#39;t contain a heteroatom? . mol = Chem.MolFromSmiles(&#39;Clc1[nH]c(Br)c(c2ccc(Cl)c(Br)c2)c1&#39;) matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[*]-Cl&#39;,&#39;[*]-Br&#39;)], rings=getAromaticRings(mol), excludeQueries=[Chem.MolFromSmarts(sma) for sma in (&#39;[a;!#6]&#39;,)])) print(matches) drawMolWithRings(mol,matches) . [{6, 7, 8, 9, 11, 13}] . Hopefully there&#39;s some useful stuff in here for you! .",
            "url": "https://greglandrum.github.io/rdkit-blog/substructure/tutorial/2020/01/30/finding-regioisomers.html",
            "relUrl": "/substructure/tutorial/2020/01/30/finding-regioisomers.html",
            "date": " • Jan 30, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "Trying out the new tautomer canonicalization code",
            "content": "During the 2018 RDKit Google Summer of Code (GSoC) project to port MolVS to C++, doing the tautomer enumeration and canonicalization were stretch goals. Susan actually managed to complete the tautomer enumeration, but since canonicalization wasn&#39;t complete, we didn&#39;t publicize this particularly widely. As part of the work for the 2020.03 release, I implemented Matt&#39;s canonicalization scheme and we recently merged that into the RDKit core. Since this is a topic that may be contentious, and since making changes to the canonicalization algorithm post-release will have be done very deliberately, I&#39;d like to collect some feedback before we do the release in a couple of months. . The implementation attempts to exactly duplicate what is currently being done in MolVS. Here&#39;s how Matt describes the process in the MolVS documentation: . Enumerate all possible tautomers using transform rules. | Use scoring system to determine canonical tautomer. | Canonical tautomer should be “reasonable” from a chemist’s point of view, but isn’t guaranteed to be the most energetically favourable. | The scoring scheme: . aromatic ring (defined by all bonds being aromatic) consisting entirely of carbons: 250 points | other aromatic rings : 100 points | a set of substructures are scored (if present). Here&#39;s the current (as of this writing) set of substructures and their associated scores (these are defined here): . {&quot;benzoquinone&quot;, &quot;[#6]1([#6]=[#6][#6]([#6]=[#6]1)=,:[N,S,O])=,:[N,S,O]&quot;, 25}, {&quot;oxim&quot;, &quot;[#6]=[N][OH]&quot;, 4}, {&quot;C=O&quot;, &quot;[#6]=,:[#8]&quot;, 2}, {&quot;N=O&quot;, &quot;[#7]=,:[#8]&quot;, 2}, {&quot;P=O&quot;, &quot;[#15]=,:[#8]&quot;, 2}, {&quot;C=hetero&quot;, &quot;[#6]=[!#1;!#6]&quot;, 1}, {&quot;methyl&quot;, &quot;[CX4H3]&quot;, 1}, {&quot;guanidine terminal=N&quot;, &quot;[#7][#6](=[NR0])[#7H0]&quot;, 1}, {&quot;guanidine endocyclic=N&quot;, &quot;[#7;R][#6;R]([N])=[#7;R]&quot;, 2}, {&quot;aci-nitro&quot;, &quot;[#6]=[N+]([O-])[OH]&quot;, -4}}; . | one point is subtracted for each H attached to P, S, Se, or Te . | . The highest scoring tautomer is selected. In the event of ties, the tautomer with the lexicographically smaller canonical SMILES is picked. . If this is something you feel strongly about, please try the code out and see what you think. If you see behavior you really don&#39;t like, or that you think is a bug, please add a comment to the associated issue in github: https://github.com/rdkit/rdkit/issues/2908 (preferred) or reply to the thread that I will create on the rdkit-discuss mailing list. . Remember that the goal of the exercise here is not to produce the &quot;best&quot; tautomer, but to produce a canonical one (always the same result for molecules which are tautomerically equivalent). We hope that this is also reasonable - in that it doesn&#39;t make a chemist&#39;s eyes burn - but that&#39;s not the primary goal. . So how can you try it out? . This is C++ code, so you need an RDKit build done from the github master. I&#39;ve done conda builds and made them available for people to try. . At the moment I&#39;ve only built the beta version for python 3.7 on linux and windows. If you would like to do some testing on the Mac, let me know and I can do a build there too. . Here&#39;s how to setup a conda environment to use the beta: . % conda create -n py37_tautomer_beta python=3.7 jupyter % conda activate py37_tautomer_beta % conda install -c rdkit/label/beta rdkit . Ok, let&#39;s look at some examples: . from rdkit import Chem from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import Draw import rdkit print(rdkit.__version__) . 2020.03.1dev1 . RDKit WARNING: [11:00:33] Enabling RDKit 2020.03.1dev1 jupyter extensions . from rdkit.Chem.MolStandardize import rdMolStandardize . enumerator = rdMolStandardize.TautomerEnumerator() . m = Chem.MolFromSmiles(&#39;Oc1c(cccc3)c3nc2ccncc12&#39;) m . Get the canonical tautomer: . enumerator.Canonicalize(m) . The canonicalizer starts by enumerating a molecule&#39;s tautomers. If you want to see those, you can use the Enumerate() method: . tauts = enumerator.Enumerate(m) Draw.MolsToGridImage(tauts) . I find this function, which reorders the list of tautomers so that the canonical one is in the first position, really useful: . def reorderTautomers(m): enumerator = rdMolStandardize.TautomerEnumerator() canon = enumerator.Canonicalize(m) csmi = Chem.MolToSmiles(canon) res = [canon] tauts = enumerator.Enumerate(m) smis = [Chem.MolToSmiles(x) for x in tauts] stpl = sorted((x,y) for x,y in zip(smis,tauts) if x!=csmi) res += [y for x,y in stpl] return res . So now we can display all the tautomers found for a molecule. The first one drawn is the canonical one: . Draw.MolsToGridImage(reorderTautomers(m)) . Draw.MolsToGridImage(reorderTautomers(Chem.MolFromSmiles(&#39;CN=c1nc[nH]cc1&#39;))) . Draw.MolsToGridImage(reorderTautomers(Chem.MolFromSmiles(&#39;CC=CO&#39;))) . As an aside, it&#39;s worth noticing that double bond stereochemistry is removed in all tautomers if the double bond is involved in the tautomerization: . m = Chem.MolFromSmiles(&#39;C/C=C(/O)F&#39;) tauts = reorderTautomers(m) print(&#39;Original SMILES:&#39;,Chem.MolToSmiles(m)) print(&#39;Tautomers (canonical first):&#39;,[Chem.MolToSmiles(x) for x in tauts]) . Original SMILES: C/C=C(/O)F Tautomers (canonical first): [&#39;CCC(=O)F&#39;, &#39;CC=C(O)F&#39;] .",
            "url": "https://greglandrum.github.io/rdkit-blog/prototypes/technical/2020/01/25/trying-the-tautomer-canonicalization-code.html",
            "relUrl": "/prototypes/technical/2020/01/25/trying-the-tautomer-canonicalization-code.html",
            "date": " • Jan 25, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "Some thoughts on the performance of the RDKit cartridge",
            "content": "EDITED on 23.01.2020 John Mayfield pointed out that the way I had constructed the set of 10 million molecules wasn’t reproducible. This update fixes that, but it also changes the results. . It’s been a while since I did a post about the cartridge! This one is a little bit ranty, but hopefully it’s still useful. . Some background and disclaimers . I normally do performance testing on the cartridge using ChEMBL, but since that’s “only” around 1.7 million compounds I wanted to try something a bit bigger. But how big? I don’t see the point in shoving 100 million compounds (or a billion) into PostgreSQL (there’s a mini-rant explaining this at the bottom of the post), so I went with 10 million. That’s more than five times bigger than ChEMBL, but it’s still not unimaginable that you’d actually have a relational schema with a molecule table this size that has data about most of those molecules in separate tables (again, see the mini-rant). . My goal here is to get a sense for what kind of performance you can expect for doing “normal” chemical queries using a local PostgreSQL instance without having to spend time optimizing the database or hardware configuration. I generated all the numbers below on my Linux desktop - which is 4-5 years old at this point - using an out-of-the-box install of PostgreSQL 12 (the only configuration tuning was to increase the size of shared_buffers to 4096M and work_mem as described in the RDKit docs). I was also using the machine for other things (like reading email or writing this post in Chrome) while these queries ran, so the numbers are really just ballpark estimates. . So which molecules to use? Rather than agonizing overly much about this, I just grabbed a PubChem Compound SMILES dump and took the first 10 million molecules from that. . I hedged above by saying “normal” chemical queries. I have a longer rant about that topic that I will spare you the details of, but I generally think that including worst-case queries (i.e. things that return tens or hundreds of thousands of rows) in real-world benchmarking examples is pointless. It’s definitely useful to understand the worst-case performance of a system, but that’s not what I’m doing here. So my queries will often limit the number of rows returned to what I think is a “reasonable” number for interactive usage. . Creating the database . This tends to be time consuming, particularly creating the molecule index. Start by creating the database from the command line and loading all of the raw data: . glandrum@otter:/tmp/pubchem_load$ createdb pubchem_compound glandrum@otter:/tmp/pubchem_load$ psql -c &#39;create extension rdkit&#39; pubchem_compound CREATE EXTENSION glandrum@otter:/tmp/pubchem_load$ psql -c &#39;create table raw_data (id SERIAL,cid integer, smiles text)&#39; pubchem_compound CREATE TABLE glandrum@otter:/tmp/pubchem_load$ zcat CID-SMILES.gz | sed &#39;s/ / /g&#39; | psql -c &quot;copy raw_data (cid,smiles) from stdin with delimiter E&#39; t&#39;&quot; pubchem_compound COPY 102397130 . Now create the molecule table and build the index: . pubchem_compound=# alter table raw_data add primary key (cid); ALTER TABLE pubchem_compound=# timing Timing is on. pubchem_compound=# select * into mols from (select cid,mol_from_smiles(smiles::cstring) m from raw_data order by cid limit 10000000) tmp where m is not null; ... lots of info about failing molecules deleted here WARNING: could not create molecule from SMILES &#39;[B+]12(CC3CC(C1)CC(C2)C3)NCC[O-]&#39; WARNING: could not create molecule from SMILES &#39;[B+]12(CC3CC(C1)CC(C2)C3)NCCO&#39; SELECT 9999165 Time: 1722464.775 ms (28:42.465) pubchem_compound=# create index molidx on mols using gist(m); CREATE INDEX Time: 3735718.147 ms (01:02:15.718) . Add fingerprints and their index along with the primary keys we’ll use to link things: . pubchem_compound=# create index fps_mfp2_idx on fps using gist(mfp2); CREATE INDEX Time: 155112.279 ms (02:35.112) pubchem_compound=# alter table mols add primary key (cid); ALTER TABLE Time: 44271.680 ms (00:44.272) pubchem_compound=# alter table fps add primary key (cid); ALTER TABLE Time: 27675.441 ms (00:27.675) . Now let’s do some queries. . Substructure queries . Note that all of the results below are done with a “warm” disk cache: I ran a substructure search and similarity search to try and ensure that at least parts of the indices are being cached by the operating system. . Picking the queries for a demo is always tricky, and can obviously completely slant the results one way or another, so I went to the ASAP page for J Med Chem and pulled stuff from there. . Let’s start with a query for parts of the “head” and “gate” from this paper: https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b01912 . pubchem_compound=# select * from mols where m@&gt;&#39;CC1=C(C=C(C=C1)C(N)=O)C#CC1=CN=CC=C1&#39; limit 10; cid | m -+- 11526637 | Cc1ccc(C(=O)Nc2cc(OC[C@@H]3CCCN3C)cc(C(F)(F)F)c2)cc1C#Cc1cnc2nc[nH]c2c1 (1 row) Time: 5359.046 ms (00:05.359) . Here’s the one hit: . . Now the core from: https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b01427 . pubchem_compound=# select * from mols where m@&gt;&#39;CC1=CC2=C(S1)C(=O)NC(C)=N2&#39; limit 10; cid | m -+ 3758971 | CCOC(=O)C1CCCn2c1nc1cc(-c3ccccc3)sc1c2=O 10622152 | COc1ccc(NC(=S)Nn2c(C)nc3cc(-c4ccccc4)sc3c2=O)cc1 1040399 | COC(=O)[C@@H]1CCc2nc3cc(-c4ccc(OC)cc4)sc3c(=O)n21 1040400 | COC(=O)[C@H]1CCc2nc3cc(-c4ccc(OC)cc4)sc3c(=O)n21 3310123 | O=c1c2sc(-c3ccccc3)cc2nc2n1CCCCC2 4376566 | CCOC(=O)C1CCCn2c1nc1cc(-c3ccc(OC)cc3)sc1c2=O 10574247 | COc1ccccc1NC(=S)Nn1c(C)nc2cc(-c3ccccc3)sc2c1=O 11404362 | Cc1cc2nc(-c3ccccc3)n(-c3ccccc3)c(=O)c2s1 10716322 | Cc1cccc(NC(=S)Nn2c(C)nc3cc(-c4ccccc4)sc3c2=O)c1 661611 | COc1ccc(-c2cc3nc4n(c(=O)c3s2)CCOC4)cc1 (10 rows) Time: 6.532 ms . And the results: . . And, finally, the core from: https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b01684 . pubchem_compound=# select * from mols where m@&gt;&#39;CN1C(=O)N(C)C2=C1C=NC(N)=N2&#39; limit 10; cid | m -+ 10359733 | C=CCn1c(=O)n(CCCCCCCC)c2nc(N)nc(Cl)c21 10452174 | Nc1nc2c(c(=O)n1N)n(CCCl)c(=O)n2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1O 10048317 | Nc1nc2c(c(=O)n1N)n(C/C=C/c1ccccc1)c(=O)n2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1O 10454396 | [N-]=[N+]=NCC(O)Cn1c(=O)n([C@@H]2O[C@H](CO)[C@@H](O)[C@H]2O)c2nc(N)n(N)c(=O)c21 10476329 | Nc1nc2c(c(=O)n1N)n(Cc1ccccc1)c(=O)n2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1O 11428584 | C=CCn1c(=O)n([C@@H]2O[C@H](CO)[C@@H](O)[C@H]2O)c2nc(N)nc(OCC)c21 11453816 | C=CCn1c(=O)n([C@@H]2O[C@H](CO)[C@@H](O)[C@H]2O)c2nc(N)nc(OCN(C)C(=O)OCC)c21 9980347 | COc1ccc(Cn2c(=O)n([C@@H]3O[C@H](CO)[C@@H](O)[C@H]3O)c3nc(N)n(N)c(=O)c32)cc1 10085856 | Cn1c(=O)n2c3c1c(=O)nc(N)n3C[C@H]1O[C@@H]2[C@H](O)[C@@H]1O 9994808 | C=CCn1c(=O)n(CCCCO)c2nc(N)nc(Cl)c21 (10 rows) Time: 107.934 ms . And the first results: . . These queries are, in general, pretty quick. I’m certainly likely to spend more time looking at the results than I am waiting for them to come back. . One point it’s worth making is that queries that don’t return any results tend to be pretty fast. Here’s an example of that: . pubchem_compound=# select * from mols where m@&gt;&#39;O1C=NC2=C1N=C1N=CN=CC1=N2&#39; limit 5; cid | m --+ (0 rows) Time: 9.778 ms . Note that this is definitely not always true… the index does not work particularly well for queries that have massively repeating common substructures: . pubchem_compound=# select * from mols where m@&gt;&#39;COCOCOCOCOCOCOCOCOCOCOCOCOCOCOCOCOCOCCOCOCOCOCOCCO&#39; limit 5; cid | m --+ (0 rows) Time: 150521.647 ms (02:30.522) . Remember what I said about about worst-case performance? There ya go. . Similarity queries . Now let’s do some similarity searches using the molecule drawn in the graphical abstract as queries. For this blog post I’m going to use the cartridge’s “neighbor” operator &lt;%&gt; to order the results and allow the N closest neighbors of each query molecule to be retrieved. Here’s the simple SQL function that I use for doing that: . pubchem_compound=# pubchem_compound=# create or replace function get_mfp2_neighbors2(smiles text) returns table(cid integer, m mol, similarity double precision) as $$ select cid,m,tanimoto_sml(morganbv_fp(mol_from_smiles($1::cstring)),mfp2) as similarity from fps join mols using (cid) order by morganbv_fp(mol_from_smiles($1::cstring))&lt;%&gt;mfp2; $$ language sql stable ; . That’s adapted from the function get_mfp2_neighbors that is in the RDKit cartridge documentation. . Let’s start with a query for the five nearest neighbors of balovaptan (https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b01478): . pubchem_compound=# select * from get_mfp2_neighbors2(&#39;CN1CC2=NN=C(C3CCC(CC3)OC3=CC=CC=N3)N2C2=CC=C(Cl)C=C2C1&#39;) limit 5; cid | m | similarity -+-+-- 11237434 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1 | 0.7049180327868853 11237433 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1.Cl.Cl.Cl | 0.6935483870967742 10070061 | CN1CCc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1 | 0.6212121212121212 11270862 | Cc1ccccc1CC(=O)N1CCC(c2nnc3n2-c2ccc(Cl)cc2CN(C)C3)CC1 | 0.5797101449275363 11442570 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(C(=O)c3c[nH]c4ccccc34)CC2)C1 | 0.5774647887323944 (5 rows) Time: 239.879 ms . It’s easy (and quick) to expand that to the ten nearest neighbors: . pubchem_compound=# select * from get_mfp2_neighbors2(&#39;CN1CC2=NN=C(C3CCC(CC3)OC3=CC=CC=N3)N2C2=CC=C(Cl)C=C2C1&#39;) limit 10; cid | m | similarity -+-+-- 11237434 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1 | 0.7049180327868853 11237433 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1.Cl.Cl.Cl | 0.6935483870967742 10070061 | CN1CCc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1 | 0.6212121212121212 11270862 | Cc1ccccc1CC(=O)N1CCC(c2nnc3n2-c2ccc(Cl)cc2CN(C)C3)CC1 | 0.5797101449275363 11442570 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(C(=O)c3c[nH]c4ccccc34)CC2)C1 | 0.5774647887323944 11486399 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(C(=O)CC3CC3)CC2)C1 | 0.5757575757575758 11349733 | CCCC(=O)N1CCC(c2nnc3n2-c2ccc(Cl)cc2CN(C)C3)CC1 | 0.5757575757575758 11305733 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(C(=O)c3cc4ccccc4[nH]3)CC2)C1 | 0.5694444444444444 11166614 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(C(=O)C3(C)CCCCC3)CC2)C1 | 0.5671641791044776 10028677 | CN1CCOC(CN2Cc3cc(Cl)ccc3-n3c(nnc3C3CCN(c4ccccn4)CC3)C2)C1 | 0.5616438356164384 (10 rows) Time: 189.425 ms . Here are the first few of those, along with the similarity values: . . The five nearest neighbors for AZD7648 (https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b01684) aren’t particularly similar: . pubchem_compound=# select * from get_mfp2_neighbors2(&#39;CN1C(=O)N(C2CCOCC2)C2=C1C=NC(NC1=CN3N=CN=C3C=C1C)=N2&#39;) limit 5; cid | m | similarity -+--+ 11504903 | Cn1c(=O)c(=O)n(C2CCCC2)c2nc(Nc3ccc(C(=O)NC4CCC(N5CCOCC5)CC4)cc3)ncc21 | 0.4166666666666667 11406590 | Cn1c(=O)c(Oc2ccc(F)cc2F)cc2cnc(NC3CCOCC3)nc21 | 0.3924050632911392 10230233 | Cc1cc(=O)n(C2CCCC2)c2nc(Nc3ccc(N4CCC(CCCN5CCOCC5)CC4)cc3)ncc12 | 0.3595505617977528 9801449 | Cc1nc2cnc(Nc3ccc(N4CCOCC4)cc3)nc2n(C2CCCC2)c1=O | 0.35443037974683544 10224126 | Cc1cc(=O)n(C2CCCC2)c2nc(Nc3ccc(N4CCOCC4)c(F)c3)ncc12 | 0.3488372093023256 (5 rows) Time: 219.653 ms . As we can see: . . The performance of these queries isn’t quite as good as what you can do with specialized open-source tools like chemfp, gpusimilarity, or FPSim2, but I think it’s reasonable for retrieving a set of neighbors that I’m then going to do (probably more time consuming) further analysis on. . Note that the similarity queries were considerably slower in the original version of this blog post. This was likely due to me doing a bad job of warming up the disk cache. . Some technical details: . Sizes of the tables and indices . pubchem_compound=# d+ List of relations Schema | Name | Type | Owner | Size | Description --+--+-+-++- public | fps | table | glandrum | 964 MB | public | mols | table | glandrum | 4236 MB | public | raw_data | table | glandrum | 9091 MB | public | raw_data_id_seq | sequence | glandrum | 8192 bytes | (4 rows) pubchem_compound=# di+ List of relations Schema | Name | Type | Owner | Table | Size | Description --++-+-+-++- public | fps_mfp2_idx | index | glandrum | fps | 1226 MB | public | fps_pkey | index | glandrum | fps | 214 MB | public | molidx | index | glandrum | mols | 4060 MB | public | mols_pkey | index | glandrum | mols | 214 MB | public | raw_data_pkey | index | glandrum | raw_data | 2193 MB | (5 rows) . Performance of the substructure indices . Here are results for the substructure queries executed above. For the purposes of this analysis I removed the limit on the query: . pubchem_compound=# explain analyze select * from mols where m@&gt;&#39;CC1=C(C=C(C=C1)C(N)=O)C#CC1=CN=CC=C1&#39;; QUERY PLAN Bitmap Heap Scan on mols (cost=2157.91..37897.03 rows=9999 width=398) (actual time=167.546..168.902 rows=1 loops=1) Recheck Cond: (m @&gt; &#39;Cc1ccc(C(N)=O)cc1C#Cc1cccnc1&#39;::mol) Rows Removed by Index Recheck: 328 Heap Blocks: exact=309 -&gt; Bitmap Index Scan on molidx (cost=0.00..2155.41 rows=9999 width=0) (actual time=137.703..137.703 rows=329 loops=1) Index Cond: (m @&gt; &#39;Cc1ccc(C(N)=O)cc1C#Cc1cccnc1&#39;::mol) Planning Time: 0.119 ms Execution Time: 169.178 ms (8 rows) pubchem_compound=# explain analyze select * from mols where m@&gt;&#39;CC1=CC2=C(S1)C(=O)NC(C)=N2&#39;; QUERY PLAN -- Bitmap Heap Scan on mols (cost=2157.91..37897.03 rows=9999 width=398) (actual time=436.998..510.558 rows=46 loops=1) Recheck Cond: (m @&gt; &#39;Cc1nc2cc(C)sc2c(=O)[nH]1&#39;::mol) Rows Removed by Index Recheck: 14 Heap Blocks: exact=55 -&gt; Bitmap Index Scan on molidx (cost=0.00..2155.41 rows=9999 width=0) (actual time=436.902..436.902 rows=60 loops=1) Index Cond: (m @&gt; &#39;Cc1nc2cc(C)sc2c(=O)[nH]1&#39;::mol) Planning Time: 0.113 ms Execution Time: 510.801 ms (8 rows) pubchem_compound=# explain analyze select * from mols where m@&gt;&#39;CN1C(=O)N(C)C2=C1C=NC(N)=N2&#39;; QUERY PLAN - Bitmap Heap Scan on mols (cost=2157.91..37897.03 rows=9999 width=398) (actual time=5111.590..5113.136 rows=38 loops=1) Recheck Cond: (m @&gt; &#39;Cn1c(=O)n(C)c2nc(N)ncc21&#39;::mol) Rows Removed by Index Recheck: 10 Heap Blocks: exact=48 -&gt; Bitmap Index Scan on molidx (cost=0.00..2155.41 rows=9999 width=0) (actual time=5081.767..5081.768 rows=48 loops=1) Index Cond: (m @&gt; &#39;Cn1c(=O)n(C)c2nc(N)ncc21&#39;::mol) Planning Time: 0.058 ms Execution Time: 5113.296 ms (8 rows) . All of those show that the index is doing a reasonably good job of pruning compounds - the worst case query (the first one) only ends up trying at 329 substructure queries (instead of 10 million!) to find the 1 actual match. . Warming up the disk cache . There are tons of ways to do this. Here’s the approach I used for this post: . pubchem_compound=# select cid,mol_murckoscaffold(m) scaff into temporary table scaffs from mols order by cid desc limit 10; SELECT 10 pubchem_compound=# select count(*) from mols cross join scaffs where mols.m@&gt;scaffs.scaff; count -- 178828 (1 row) pubchem_compound=# select * into blah from fps order by cid desc limit 10; SELECT 10 pubchem_compound=# select count(*) from fps cross join blah where blah.mfp2%fps.mfp2; count - 401 (1 row) . That takes ~10 minutes to run for me. . Doing the queries and making the images . Since I’m not doing this one from a jupyter notebook, here’s the code snippet I’m using in jupyter to do the substructure queries and display the results: . q=&#39;CN1C(=O)N(C)C2=C1C=NC(N)=N2&#39; t1=time.time() d = %sql postgresql://localhost/pubchem_compound select * from mols where m@&gt;:q limit 10; t2 = time.time() print(f&#39;{t2-t1:.2f} seconds&#39;) ms = [Chem.MolFromSmiles(x) for x in [q]+[x[1] for x in d]] ls = [&#39;query&#39;]+[str(x[0]) for x in d] Draw.MolsToGridImage(ms[:8],legends=ls,molsPerRow=4) . And the equivalent thing for nearest-neighbor queries: . q=&#39;CN1CC2=NN=C(C3CCC(CC3)OC3=CC=CC=N3)N2C2=CC=C(Cl)C=C2C1&#39; t1=time.time() d = %sql postgresql://localhost/pubchem_compound select * from get_mfp2_neighbors2(:q) limit 10; t2 = time.time() print(f&#39;{t2-t1:.2f} seconds&#39;) ms = [Chem.MolFromSmiles(x) for x in [q]+[x[1] for x in d]] ls = [&#39;query&#39;]+[f&#39;{x[0]} {x[2] :.2f}&#39; for x in d] Draw.MolsToGridImage(ms[:8],legends=ls,molsPerRow=4) . Both of these are using the fantastic sql-magic for jupyter from Catherine Devlin. . Mini-rant . PostgreSQL is a general purpose relational database, it lets you store collections of tables with links (relations) between them and makes it easy to do queries that combine data across tables. If you have data on a bunch of molecules that can’t be logically captured in a single table (like ChEMBL!), a relational database is a great place to put that. If you have a single table with a bunch of columns (i.e. molecules and values or fingerprints computed from them), you may want to look to another type of system. If you have a huge number of rows that you are really only interested in doing chemical queries (substructure and similarity searches) against, and you care about performance, then you almost certainly should be using a specialized system. There are plenty to choose from! .",
            "url": "https://greglandrum.github.io/rdkit-blog/cartridge/2020/01/21/some-thoughts-on-cartridge-performance.html",
            "relUrl": "/cartridge/2020/01/21/some-thoughts-on-cartridge-performance.html",
            "date": " • Jan 21, 2020"
        }
        
    
  
    
        ,"post15": {
            "title": "Similarity maps with the new drawing code",
            "content": "As part of the 2019.09 release we added a C++ implementation of the RDKit&#39;s similarity map functionality (https://jcheminf.biomedcentral.com/articles/10.1186/1758-2946-5-43). I forgot to mention this during the &quot;What&#39;s New&quot; bit of my presentation at the UGM, but I think it&#39;s worth calling attention to. So here&#39;s a quick blog post. . from rdkit import Chem from rdkit.Chem import Draw from rdkit.Chem.Draw import SimilarityMaps from IPython.display import SVG import io from PIL import Image import numpy as np import rdkit print(rdkit.__version__) . RDKit WARNING: [11:53:45] Enabling RDKit 2019.09.2 jupyter extensions . 2019.09.2 . I start by using &quot;classic&quot; similarity map functionality to show why atorvastatin (Lipitor) and rosuvastatin (Crestor) are similar to each other when using the Morgan fingerprint. . Here are the two molecules: . atorvastatin = Chem.MolFromSmiles(&#39;O=C(O)C[C@H](O)C[C@H](O)CCn2c(c(c(c2c1ccc(F)cc1)c3ccccc3)C(=O)Nc4ccccc4)C(C)C&#39;) rosuvastatin = Chem.MolFromSmiles(&#39;OC(=O)C[C@H](O)C[C@H](O) C=C c1c(C(C)C)nc(N(C)S(=O)(=O)C)nc1c2ccc(F)cc2&#39;) Draw.MolsToGridImage((atorvastatin,rosuvastatin)) . To use the new drawing code, we create a Draw2D object and pass that to SimilarityMaps.GetSimilarityMapForFingerprint: . def show_png(data): bio = io.BytesIO(data) img = Image.open(bio) return img . d = Draw.MolDraw2DCairo(400, 400) _, maxWeight = SimilarityMaps.GetSimilarityMapForFingerprint(atorvastatin, rosuvastatin, lambda m, i: SimilarityMaps.GetMorganFingerprint(m, i, radius=2, fpType=&#39;bv&#39;), draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . We can do the same thing with count-based fingerprints: . d = Draw.MolDraw2DCairo(400, 400) _, maxWeight = SimilarityMaps.GetSimilarityMapForFingerprint(atorvastatin, rosuvastatin, lambda m, i: SimilarityMaps.GetMorganFingerprint(m, i, radius=2, fpType=&#39;count&#39;), draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . The other GetSimilarityMapFrom... functions also accept the optional draw2d argument. Here&#39;s a visualization of the contributions made by the atoms in atorvastatin to its calculatied logp value: . from rdkit.Chem import rdMolDescriptors ator_contribs = rdMolDescriptors._CalcCrippenContribs(atorvastatin) d = Draw.MolDraw2DCairo(400, 400) SimilarityMaps.GetSimilarityMapFromWeights(atorvastatin,[x[0] for x in ator_contribs],draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . And a couple more visualizations of various partial charge schemes. . Starting with Gasteiger-Marsilli charges: . from rdkit.Chem import rdPartialCharges rdPartialCharges.ComputeGasteigerCharges(atorvastatin) chgs = [x.GetDoubleProp(&quot;_GasteigerCharge&quot;) for x in atorvastatin.GetAtoms()] d = Draw.MolDraw2DCairo(400, 400) SimilarityMaps.GetSimilarityMapFromWeights(atorvastatin,chgs,draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . And also the partial charges calculated with extended Hueckel theory (eHT) using Mulliken analysis: . from rdkit.Chem import rdEHTTools from rdkit.Chem import rdDistGeom mh = Chem.AddHs(atorvastatin) rdDistGeom.EmbedMolecule(mh) _,res = rdEHTTools.RunMol(mh) static_chgs = res.GetAtomicCharges()[:atorvastatin.GetNumAtoms()] d = Draw.MolDraw2DCairo(400, 400) SimilarityMaps.GetSimilarityMapFromWeights(atorvastatin,list(static_chgs),draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . As one final demo, I&#39;ll use the method to visualize the variability of the eHT charges with conformation for atorvastatin. . Start by generating 10 diverse conformers, calculating the charges for each, and plotting the average: . mh = Chem.AddHs(atorvastatin) ps = rdDistGeom.ETKDGv2() ps.pruneRmsThresh = 0.5 ps.randomSeed = 0xf00d rdDistGeom.EmbedMultipleConfs(mh,10,ps) print(f&#39;Found {mh.GetNumConformers()} conformers&#39;) chgs = [] for conf in mh.GetConformers(): _,res = rdEHTTools.RunMol(mh,confId=conf.GetId()) chgs.append(res.GetAtomicCharges()[:atorvastatin.GetNumAtoms()]) chgs = np.array(chgs) mean_chgs = np.mean(chgs,axis=0) std_chgs = np.std(chgs,axis=0) d = Draw.MolDraw2DCairo(400, 400) SimilarityMaps.GetSimilarityMapFromWeights(atorvastatin,list(mean_chgs),draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . Found 10 conformers . That doesn&#39;t look hugely different from what we saw above. . To show the variability, plot the standard deviation of the charges across the 10 conformers: . print(std_chgs) print(max(std_chgs),min(std_chgs)) d = Draw.MolDraw2DCairo(400, 400) SimilarityMaps.GetSimilarityMapFromWeights(atorvastatin,list(std_chgs),draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . [0.01292592 0.00743163 0.01971312 0.01433223 0.01063085 0.01283745 0.01219511 0.00748435 0.01234194 0.01492494 0.00640842 0.02264999 0.02481744 0.00987842 0.00843151 0.01289956 0.00560632 0.00498617 0.00604883 0.005569 0.00452067 0.00796675 0.00718033 0.00581337 0.00702613 0.00634237 0.00699789 0.00539868 0.00521868 0.02412709 0.03131741 0.03709349 0.00657276 0.01175903 0.00674661 0.01012909 0.0050995 0.01139418 0.00831795 0.00581207 0.00960073] 0.03709348867462464 0.00452067345998171 . The deviations aren&#39;t huge (the printed array shows that), but the largest value is clearly the amide N. . There&#39;s definitely a ToDo here to improve the way the negative contours are drawn so that the fact that they are being drawn with dashed lines is visible. .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/2020/01/03/similarity-maps-with-new-drawing-code.html",
            "relUrl": "/tutorial/2020/01/03/similarity-maps-with-new-drawing-code.html",
            "date": " • Jan 3, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About this blog",
          "content": "The repo with the original Jupyter notebooks and data is here . The hub for information about the RDKit is rdkit.org . If you’re an Anaconda Python user, installing the RDKit is as simple as conda install -c conda-forge rdkit . Professional support and services for the RDKit are provided by T5 Informatics GmbH. Contact us if you are interested in RDKit support. . . This blog is powered by fastpages. .",
          "url": "https://greglandrum.github.io/rdkit-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://greglandrum.github.io/rdkit-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}